{
  
    
        "post0": {
            "title": "Final Project: Comparing Artists Across Countries",
            "content": "DH 140 Final Project W22 . Spurthi Rallapalli, Cindy Zheng, Carol Cheng 3/11/22 . Comparing Artists Across Countries . Group Member Contribution: . Spurthi: Preliminary Data Analysis | Cindy: Maps + Advanced Data Analysis | Carol: Lyrical Analysis | . Research Topic Introduction . Research Question: Our research question is &quot;How does a song&#39;s popularity spread over time depending on the origin country of the artist, and how much of that is attributed to the lyrics / word patterns in that song?&quot; . For this analysis, we specifically picked two artists from the United States and the UK, analyzed the popularity of their songs, and did a lyrical analysis. . Why it is important to you, why it matters to others, and what is at stake: Music is something that everyone connects to, and our group wants to find a way to measure how and why music is spread across the world. It’s a way for musicians to figure out which kind of music allows them to connect with different audiences and cross cultural and linguistic barriers. It’s also a way for us as listeners to help determine what connects us to certain kinds of music, what word frequencies and thematic patterns matter most to us, and what cultural practices and norms cause certain groups to listen (or not to listen) to certain types of music. Essentially, it’s a way to determine what connects us all! . Description of data sources used: The first data source is from Spotify Charts. Spotify Charts is a website from the popular music streaming app, Spotify. Spofity constantly keeps ranking of how often songs are streamed from their uses, and keeps track of which songs are streamed the most. Spotify also separates these streaming counts by country. The top 200 songs of each day or week and their total streams are available to download in csv format from Spotify Charts. The data can be found at https://spotifycharts.com/. . The second data source will be song lyrics. These can be found on genius.com, and we will be copying and pasting the text lyrics from those websites to perform text analysis. https://genius.com/ . Methods . Below is the code that we used to import the data into our Jupyter Notebook. We went to Spotify Charts to look at Top 200 Hits Data for every week in 2021 in the United States and the UK: . import pandas as pd import os import glob import datetime import numpy from matplotlib import pyplot as plt #import cloudscraper def readData(country): path = os.getcwd() path = os.path.join(path, &quot;Data&quot;, country, &quot;*.csv&quot;) csv_files = glob.glob(path) # loop over the list of csv files weekly_charts = pd.DataFrame() for f in csv_files: filename = os.path.basename(f) # read the csv file df = pd.read_csv(f) idx = filename.index(&#39;weekly&#39;) date_time_obj = datetime.datetime.strptime(filename[idx+7:-4], &#39;%Y-%m-%d&#39;) df[&quot;date&quot;] = date_time_obj weekly_charts= weekly_charts.append(df) return weekly_charts weekly_us_charts = readData(&quot;us&quot;) weekly_gb_charts = readData(&quot;gb&quot;) #weekly_global_charts = readData(&quot;GlobalData&quot;) . In the code above, we created a function readData that allowed us to create 2 different datasets, one for the US and one for the UK. Let&#39;s start by doing a preliminary analysis of the data. . A quick look into the data shows that there are a couple of fields that our data encompasses that are common among the two datasets: . rank | uri | arist name(s) | track name | source | peak rank | previous rank | weeks on chart | streams | date | . I also want to get a sense of which dates we are looking at across the two countries, so I&#39;m going to do a quick analysis of the date field to see which dates are included. . weekly_us_charts[&#39;date&#39;].unique() . . array([&#39;2021-10-14T00:00:00.000000000&#39;, &#39;2021-08-19T00:00:00.000000000&#39;, &#39;2021-06-03T00:00:00.000000000&#39;, &#39;2021-11-18T00:00:00.000000000&#39;, &#39;2021-01-07T00:00:00.000000000&#39;, &#39;2021-05-13T00:00:00.000000000&#39;, &#39;2021-01-14T00:00:00.000000000&#39;, &#39;2021-06-10T00:00:00.000000000&#39;, &#39;2021-08-12T00:00:00.000000000&#39;, &#39;2021-07-15T00:00:00.000000000&#39;, &#39;2021-09-30T00:00:00.000000000&#39;, &#39;2021-12-23T00:00:00.000000000&#39;, &#39;2021-03-18T00:00:00.000000000&#39;, &#39;2021-03-25T00:00:00.000000000&#39;, &#39;2021-09-16T00:00:00.000000000&#39;, &#39;2021-04-01T00:00:00.000000000&#39;, &#39;2021-03-04T00:00:00.000000000&#39;, &#39;2021-11-25T00:00:00.000000000&#39;, &#39;2021-12-02T00:00:00.000000000&#39;, &#39;2021-07-22T00:00:00.000000000&#39;, &#39;2021-06-17T00:00:00.000000000&#39;, &#39;2021-04-29T00:00:00.000000000&#39;, &#39;2021-07-01T00:00:00.000000000&#39;, &#39;2021-06-24T00:00:00.000000000&#39;, &#39;2021-05-27T00:00:00.000000000&#39;, &#39;2021-05-20T00:00:00.000000000&#39;, &#39;2021-10-28T00:00:00.000000000&#39;, &#39;2021-05-06T00:00:00.000000000&#39;, &#39;2021-09-23T00:00:00.000000000&#39;, &#39;2021-01-28T00:00:00.000000000&#39;, &#39;2021-12-16T00:00:00.000000000&#39;, &#39;2021-09-02T00:00:00.000000000&#39;, &#39;2021-02-04T00:00:00.000000000&#39;, &#39;2021-03-11T00:00:00.000000000&#39;, &#39;2021-07-29T00:00:00.000000000&#39;, &#39;2021-11-04T00:00:00.000000000&#39;, &#39;2021-02-25T00:00:00.000000000&#39;, &#39;2021-04-08T00:00:00.000000000&#39;, &#39;2021-07-08T00:00:00.000000000&#39;, &#39;2021-02-18T00:00:00.000000000&#39;, &#39;2021-08-26T00:00:00.000000000&#39;, &#39;2021-12-09T00:00:00.000000000&#39;, &#39;2021-08-05T00:00:00.000000000&#39;, &#39;2021-12-30T00:00:00.000000000&#39;, &#39;2021-10-21T00:00:00.000000000&#39;, &#39;2021-04-22T00:00:00.000000000&#39;, &#39;2021-10-07T00:00:00.000000000&#39;, &#39;2021-09-09T00:00:00.000000000&#39;, &#39;2021-11-11T00:00:00.000000000&#39;, &#39;2021-01-21T00:00:00.000000000&#39;, &#39;2021-04-15T00:00:00.000000000&#39;, &#39;2021-02-11T00:00:00.000000000&#39;], dtype=&#39;datetime64[ns]&#39;) . weekly_gb_charts[&#39;date&#39;].unique() . . array([&#39;2021-01-28T00:00:00.000000000&#39;, &#39;2021-11-25T00:00:00.000000000&#39;, &#39;2021-12-23T00:00:00.000000000&#39;, &#39;2021-06-17T00:00:00.000000000&#39;, &#39;2021-08-05T00:00:00.000000000&#39;, &#39;2021-07-15T00:00:00.000000000&#39;, &#39;2021-04-22T00:00:00.000000000&#39;, &#39;2021-09-30T00:00:00.000000000&#39;, &#39;2021-03-04T00:00:00.000000000&#39;, &#39;2021-04-29T00:00:00.000000000&#39;, &#39;2021-06-03T00:00:00.000000000&#39;, &#39;2021-04-15T00:00:00.000000000&#39;, &#39;2021-06-24T00:00:00.000000000&#39;, &#39;2021-10-07T00:00:00.000000000&#39;, &#39;2021-12-02T00:00:00.000000000&#39;, &#39;2021-09-16T00:00:00.000000000&#39;, &#39;2021-08-19T00:00:00.000000000&#39;, &#39;2021-02-25T00:00:00.000000000&#39;, &#39;2021-05-20T00:00:00.000000000&#39;, &#39;2021-09-23T00:00:00.000000000&#39;, &#39;2021-07-22T00:00:00.000000000&#39;, &#39;2021-07-29T00:00:00.000000000&#39;, &#39;2021-05-06T00:00:00.000000000&#39;, &#39;2021-07-01T00:00:00.000000000&#39;, &#39;2021-04-01T00:00:00.000000000&#39;, &#39;2021-01-21T00:00:00.000000000&#39;, &#39;2021-01-14T00:00:00.000000000&#39;, &#39;2021-11-11T00:00:00.000000000&#39;, &#39;2021-08-26T00:00:00.000000000&#39;, &#39;2021-03-18T00:00:00.000000000&#39;, &#39;2021-08-12T00:00:00.000000000&#39;, &#39;2021-02-18T00:00:00.000000000&#39;, &#39;2021-09-02T00:00:00.000000000&#39;, &#39;2021-06-10T00:00:00.000000000&#39;, &#39;2021-10-21T00:00:00.000000000&#39;, &#39;2021-02-11T00:00:00.000000000&#39;, &#39;2021-11-18T00:00:00.000000000&#39;, &#39;2021-02-04T00:00:00.000000000&#39;, &#39;2021-12-09T00:00:00.000000000&#39;, &#39;2021-05-27T00:00:00.000000000&#39;, &#39;2021-03-11T00:00:00.000000000&#39;, &#39;2021-07-08T00:00:00.000000000&#39;, &#39;2021-09-09T00:00:00.000000000&#39;, &#39;2021-12-30T00:00:00.000000000&#39;, &#39;2021-05-13T00:00:00.000000000&#39;, &#39;2021-12-16T00:00:00.000000000&#39;, &#39;2021-03-25T00:00:00.000000000&#39;, &#39;2021-11-04T00:00:00.000000000&#39;, &#39;2021-01-07T00:00:00.000000000&#39;, &#39;2021-10-14T00:00:00.000000000&#39;, &#39;2021-04-08T00:00:00.000000000&#39;, &#39;2021-10-28T00:00:00.000000000&#39;], dtype=&#39;datetime64[ns]&#39;) . For this analysis, we want to make sure that the two datasets cover the same dates, so we&#39;ll do a check right now to see if the dates are the same. . for day in weekly_us_charts[&#39;date&#39;].unique(): if day not in weekly_gb_charts[&#39;date&#39;].unique(): print(day) . for day in weekly_gb_charts[&#39;date&#39;].unique(): if day not in weekly_us_charts[&#39;date&#39;].unique(): print(day) . This means that all the dates are the same in both of the datasets! . The other thing we also noticed is that the dates are not in order, so we will try to reorder them. This link helped with that. . weekly_us_charts = weekly_us_charts.sort_values(by=[&#39;date&#39;,&#39;rank&#39;], ascending = [True, True]) . weekly_gb_charts = weekly_gb_charts.sort_values(by=[&#39;date&#39;,&#39;rank&#39;], ascending = [True, True]) . If we take a look at the first and last few values of each chart, we can see that they have been put in the right order by date and kept the ranking the same. . weekly_us_charts.head(10) . . rank uri artist_names track_name source peak_rank previous_rank weeks_on_chart streams date . 0 1 | spotify:track:3YJJjQPAbDT7mGpX3WtQ9A | SZA | Good Days | Top Dawg Entertainment/RCA Records | 1 | 10 | 2 | 6323585 | 2021-01-07 | . 1 2 | spotify:track:31qCy5ZaophVA81wtlwLc4 | Justin Bieber | Anyone | RBMG/Def Jam | 2 | -1 | 1 | 6149984 | 2021-01-07 | . 2 3 | spotify:track:6Im9k8u9iIzKMrmV7BWtlF | Ariana Grande | 34+35 | Republic Records | 2 | 2 | 10 | 5606876 | 2021-01-07 | . 3 4 | spotify:track:3tjFYV6RSFtuktYl3ZtYcq | 24kGoldn, iann dior | Mood (feat. iann dior) | Records/Columbia | 2 | 4 | 22 | 5583614 | 2021-01-07 | . 4 5 | spotify:track:7hxHWCCAIIxFLCzvDgnQHX | Internet Money, Gunna, Don Toliver, NAV | Lemonade (feat. Gunna, Don Toliver &amp; NAV) | Internet Money Records/ TenThousand Projects | 1 | 5 | 21 | 5368252 | 2021-01-07 | . 5 6 | spotify:track:4MzXwWMhyBbmu6hOcLVD49 | Bad Bunny, Jhay Cortez | DÁKITI | Rimas Entertainment LLC | 1 | 6 | 10 | 5161927 | 2021-01-07 | . 6 7 | spotify:track:35mvY5S1H3J2QZyna3TFe0 | Ariana Grande | positions | Republic Records | 1 | 9 | 11 | 5102841 | 2021-01-07 | . 7 8 | spotify:track:5vGLcdRuSbUhD8ScwsGSdA | CJ | Whoopty | CJ Music Group/T-Series | 8 | 13 | 11 | 4877062 | 2021-01-07 | . 8 9 | spotify:track:27OeeYzk6klgBh83TSvGMA | The Kid LAROI | WITHOUT YOU | Columbia | 9 | 11 | 8 | 4777818 | 2021-01-07 | . 9 10 | spotify:track:0VjIjW4GlUZAMYd2vXMi3b | The Weeknd | Blinding Lights | Republic Records | 1 | 19 | 58 | 4440447 | 2021-01-07 | . weekly_us_charts.tail(10) . . rank uri artist_names track_name source peak_rank previous_rank weeks_on_chart streams date . 190 191 | spotify:track:370oYn3s5EKu7ziUpMQQTr | Amy Grant | White Christmas | Amy Grant Label (AGG) | 65 | 127 | 11 | 1561617 | 2021-12-30 | . 191 192 | spotify:track:6tDDoYIxWvMLTdKpjFkc1B | Kali Uchis | telepatía | EMI / Interscope | 4 | 192 | 46 | 1553987 | 2021-12-30 | . 192 193 | spotify:track:2ZXxRC6V6AXzMdbLQZMHSB | Lil Tecca | LOT OF ME | Galactic / Republic Records | 65 | -1 | 13 | 1553543 | 2021-12-30 | . 193 194 | spotify:track:30QR0ndUdiiMQMA9g1PGCm | $uicideboy$ | ...And to Those I Love, Thanks for Sticking Ar... | G59 Records | 37 | -1 | 39 | 1551895 | 2021-12-30 | . 194 195 | spotify:track:2KnLkZ3z7PO3kgVGHGqDpD | Shawn Mendes | It&#39;ll Be Okay | Shawn Mendes LP4-5 PS/ Island | 100 | -1 | 2 | 1551299 | 2021-12-30 | . 195 196 | spotify:track:4jPy3l0RUwlUI9T5XHBW2m | 24kGoldn, iann dior | Mood (feat. iann dior) | Records/Columbia | 2 | -1 | 72 | 1544286 | 2021-12-30 | . 196 197 | spotify:track:2LBqCSwhJGcFQeTHMVGwy3 | The Weeknd | Die For You | Universal Republic Records | 74 | -1 | 42 | 1536551 | 2021-12-30 | . 197 198 | spotify:track:7kDUspsoYfLkWnZR7qwHZl | Machine Gun Kelly, blackbear | my ex&#39;s best friend (with blackbear) | Bad Boy/Interscope Records | 11 | 195 | 73 | 1528614 | 2021-12-30 | . 198 199 | spotify:track:3J8EOeKLTLXORtWPpOU5bE | Lil Tjay, 6LACK | Calling My Phone | Columbia | 1 | -1 | 41 | 1521613 | 2021-12-30 | . 199 200 | spotify:track:0uRrG2jRR5tuifsYIJHEao | Morgan Wallen | Sand In My Boots | Big Loud / Republic | 13 | -1 | 27 | 1518916 | 2021-12-30 | . I also wanted to do some summary statistics for each day. . days = weekly_us_charts[&#39;date&#39;].unique() . for i in days: avg_week_on_charts = 0 max_week_on_charts = 0 subset = weekly_us_charts.loc[weekly_us_charts[&#39;date&#39;] == i] avg_week_on_charts = subset[&#39;weeks_on_chart&#39;].mean() max_week_on_charts = subset[&#39;weeks_on_chart&#39;].max() avg_streams = subset[&#39;streams&#39;].mean() peak_ranking = subset[&#39;peak_rank&#39;].mode() ts = pd.to_datetime(str(i)) d = ts.strftime(&#39;%Y-%m-%d&#39;) print(&quot;Country: United States&quot;) print(&quot;Date: &quot;, d) print(&quot;Average number of weeks this week’s top 200 have been on the chart: &quot;, avg_week_on_charts) print(&quot;Maximum number of weeks this week’s top 200 have been on the chart: &quot;, max_week_on_charts) print(&quot;Average number of steams of weeks this week’s top 200: &quot;, avg_streams) print(&quot;Most common peak ranking of weeks this week’s top 200: &quot;, peak_ranking[0]) print(&quot;&quot;) . . Country: United States Date: 2021-01-07 Average number of weeks this week’s top 200 have been on the chart: 38.125 Maximum number of weeks this week’s top 200 have been on the chart: 210 Average number of steams of weeks this week’s top 200: 2209871.275 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-01-14 Average number of weeks this week’s top 200 have been on the chart: 32.755 Maximum number of weeks this week’s top 200 have been on the chart: 211 Average number of steams of weeks this week’s top 200: 2657771.18 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-01-21 Average number of weeks this week’s top 200 have been on the chart: 33.89 Maximum number of weeks this week’s top 200 have been on the chart: 212 Average number of steams of weeks this week’s top 200: 2521075.2 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-01-28 Average number of weeks this week’s top 200 have been on the chart: 36.54 Maximum number of weeks this week’s top 200 have been on the chart: 213 Average number of steams of weeks this week’s top 200: 2373012.785 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-02-04 Average number of weeks this week’s top 200 have been on the chart: 36.34 Maximum number of weeks this week’s top 200 have been on the chart: 214 Average number of steams of weeks this week’s top 200: 2326543.445 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-02-11 Average number of weeks this week’s top 200 have been on the chart: 37.15 Maximum number of weeks this week’s top 200 have been on the chart: 215 Average number of steams of weeks this week’s top 200: 2331775.955 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-02-18 Average number of weeks this week’s top 200 have been on the chart: 38.735 Maximum number of weeks this week’s top 200 have been on the chart: 216 Average number of steams of weeks this week’s top 200: 2227007.035 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-02-25 Average number of weeks this week’s top 200 have been on the chart: 39.12 Maximum number of weeks this week’s top 200 have been on the chart: 217 Average number of steams of weeks this week’s top 200: 2293503.01 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-03-04 Average number of weeks this week’s top 200 have been on the chart: 41.655 Maximum number of weeks this week’s top 200 have been on the chart: 218 Average number of steams of weeks this week’s top 200: 2277581.67 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-03-11 Average number of weeks this week’s top 200 have been on the chart: 40.32 Maximum number of weeks this week’s top 200 have been on the chart: 219 Average number of steams of weeks this week’s top 200: 2494191.93 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-03-18 Average number of weeks this week’s top 200 have been on the chart: 41.025 Maximum number of weeks this week’s top 200 have been on the chart: 220 Average number of steams of weeks this week’s top 200: 2348729.26 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-03-25 Average number of weeks this week’s top 200 have been on the chart: 38.37 Maximum number of weeks this week’s top 200 have been on the chart: 221 Average number of steams of weeks this week’s top 200: 2592883.015 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-04-01 Average number of weeks this week’s top 200 have been on the chart: 36.12 Maximum number of weeks this week’s top 200 have been on the chart: 222 Average number of steams of weeks this week’s top 200: 2511194.525 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-04-08 Average number of weeks this week’s top 200 have been on the chart: 39.87 Maximum number of weeks this week’s top 200 have been on the chart: 223 Average number of steams of weeks this week’s top 200: 2482201.855 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-04-15 Average number of weeks this week’s top 200 have been on the chart: 33.015 Maximum number of weeks this week’s top 200 have been on the chart: 224 Average number of steams of weeks this week’s top 200: 2751792.255 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-04-22 Average number of weeks this week’s top 200 have been on the chart: 39.195 Maximum number of weeks this week’s top 200 have been on the chart: 225 Average number of steams of weeks this week’s top 200: 2503534.495 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-04-29 Average number of weeks this week’s top 200 have been on the chart: 40.87 Maximum number of weeks this week’s top 200 have been on the chart: 226 Average number of steams of weeks this week’s top 200: 2427072.74 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-05-06 Average number of weeks this week’s top 200 have been on the chart: 38.435 Maximum number of weeks this week’s top 200 have been on the chart: 227 Average number of steams of weeks this week’s top 200: 2486904.03 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-05-13 Average number of weeks this week’s top 200 have been on the chart: 39.89 Maximum number of weeks this week’s top 200 have been on the chart: 228 Average number of steams of weeks this week’s top 200: 2432577.765 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-05-20 Average number of weeks this week’s top 200 have been on the chart: 35.145 Maximum number of weeks this week’s top 200 have been on the chart: 229 Average number of steams of weeks this week’s top 200: 2993777.98 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-05-27 Average number of weeks this week’s top 200 have been on the chart: 34.425 Maximum number of weeks this week’s top 200 have been on the chart: 230 Average number of steams of weeks this week’s top 200: 3205930.275 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-06-03 Average number of weeks this week’s top 200 have been on the chart: 38.535 Maximum number of weeks this week’s top 200 have been on the chart: 231 Average number of steams of weeks this week’s top 200: 2817462.31 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-06-10 Average number of weeks this week’s top 200 have been on the chart: 34.98 Maximum number of weeks this week’s top 200 have been on the chart: 232 Average number of steams of weeks this week’s top 200: 2753536.78 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-06-17 Average number of weeks this week’s top 200 have been on the chart: 27.965 Maximum number of weeks this week’s top 200 have been on the chart: 233 Average number of steams of weeks this week’s top 200: 2773158.59 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-06-24 Average number of weeks this week’s top 200 have been on the chart: 36.76 Maximum number of weeks this week’s top 200 have been on the chart: 234 Average number of steams of weeks this week’s top 200: 2514915.4 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-07-01 Average number of weeks this week’s top 200 have been on the chart: 30.49 Maximum number of weeks this week’s top 200 have been on the chart: 235 Average number of steams of weeks this week’s top 200: 2913348.125 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-07-08 Average number of weeks this week’s top 200 have been on the chart: 30.535 Maximum number of weeks this week’s top 200 have been on the chart: 236 Average number of steams of weeks this week’s top 200: 2528940.925 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-07-15 Average number of weeks this week’s top 200 have been on the chart: 34.7 Maximum number of weeks this week’s top 200 have been on the chart: 237 Average number of steams of weeks this week’s top 200: 2574424.81 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-07-22 Average number of weeks this week’s top 200 have been on the chart: 31.425 Maximum number of weeks this week’s top 200 have been on the chart: 238 Average number of steams of weeks this week’s top 200: 2545951.65 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-07-29 Average number of weeks this week’s top 200 have been on the chart: 33.99 Maximum number of weeks this week’s top 200 have been on the chart: 239 Average number of steams of weeks this week’s top 200: 2519987.11 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-08-05 Average number of weeks this week’s top 200 have been on the chart: 33.74 Maximum number of weeks this week’s top 200 have been on the chart: 240 Average number of steams of weeks this week’s top 200: 2592660.075 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-08-12 Average number of weeks this week’s top 200 have been on the chart: 35.13 Maximum number of weeks this week’s top 200 have been on the chart: 241 Average number of steams of weeks this week’s top 200: 2452615.03 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-08-19 Average number of weeks this week’s top 200 have been on the chart: 35.63 Maximum number of weeks this week’s top 200 have been on the chart: 242 Average number of steams of weeks this week’s top 200: 2425158.48 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-08-26 Average number of weeks this week’s top 200 have been on the chart: 33.93 Maximum number of weeks this week’s top 200 have been on the chart: 243 Average number of steams of weeks this week’s top 200: 2477370.88 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-09-02 Average number of weeks this week’s top 200 have been on the chart: 30.39 Maximum number of weeks this week’s top 200 have been on the chart: 244 Average number of steams of weeks this week’s top 200: 2997656.69 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-09-09 Average number of weeks this week’s top 200 have been on the chart: 28.79 Maximum number of weeks this week’s top 200 have been on the chart: 245 Average number of steams of weeks this week’s top 200: 3572951.305 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-09-16 Average number of weeks this week’s top 200 have been on the chart: 28.78 Maximum number of weeks this week’s top 200 have been on the chart: 246 Average number of steams of weeks this week’s top 200: 2728534.855 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-09-23 Average number of weeks this week’s top 200 have been on the chart: 31.725 Maximum number of weeks this week’s top 200 have been on the chart: 247 Average number of steams of weeks this week’s top 200: 2746246.2 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-09-30 Average number of weeks this week’s top 200 have been on the chart: 34.2 Maximum number of weeks this week’s top 200 have been on the chart: 248 Average number of steams of weeks this week’s top 200: 2497293.805 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-10-07 Average number of weeks this week’s top 200 have been on the chart: 36.785 Maximum number of weeks this week’s top 200 have been on the chart: 249 Average number of steams of weeks this week’s top 200: 2362499.62 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-10-14 Average number of weeks this week’s top 200 have been on the chart: 36.9 Maximum number of weeks this week’s top 200 have been on the chart: 250 Average number of steams of weeks this week’s top 200: 2306068.12 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-10-21 Average number of weeks this week’s top 200 have been on the chart: 34.075 Maximum number of weeks this week’s top 200 have been on the chart: 251 Average number of steams of weeks this week’s top 200: 2441207.705 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-10-28 Average number of weeks this week’s top 200 have been on the chart: 35.58 Maximum number of weeks this week’s top 200 have been on the chart: 252 Average number of steams of weeks this week’s top 200: 2352557.905 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-11-04 Average number of weeks this week’s top 200 have been on the chart: 36.35 Maximum number of weeks this week’s top 200 have been on the chart: 253 Average number of steams of weeks this week’s top 200: 2293509.82 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-11-11 Average number of weeks this week’s top 200 have been on the chart: 35.645 Maximum number of weeks this week’s top 200 have been on the chart: 254 Average number of steams of weeks this week’s top 200: 2388926.38 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-11-18 Average number of weeks this week’s top 200 have been on the chart: 30.385 Maximum number of weeks this week’s top 200 have been on the chart: 255 Average number of steams of weeks this week’s top 200: 3063199.68 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-11-25 Average number of weeks this week’s top 200 have been on the chart: 31.56 Maximum number of weeks this week’s top 200 have been on the chart: 256 Average number of steams of weeks this week’s top 200: 2751508.76 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-12-02 Average number of weeks this week’s top 200 have been on the chart: 32.1 Maximum number of weeks this week’s top 200 have been on the chart: 257 Average number of steams of weeks this week’s top 200: 2548464.04 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-12-09 Average number of weeks this week’s top 200 have been on the chart: 32.34 Maximum number of weeks this week’s top 200 have been on the chart: 243 Average number of steams of weeks this week’s top 200: 2797007.995 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-12-16 Average number of weeks this week’s top 200 have been on the chart: 30.045 Maximum number of weeks this week’s top 200 have been on the chart: 244 Average number of steams of weeks this week’s top 200: 2958196.605 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-12-23 Average number of weeks this week’s top 200 have been on the chart: 27.81 Maximum number of weeks this week’s top 200 have been on the chart: 245 Average number of steams of weeks this week’s top 200: 3045547.8 Most common peak ranking of weeks this week’s top 200: 1 Country: United States Date: 2021-12-30 Average number of weeks this week’s top 200 have been on the chart: 31.45 Maximum number of weeks this week’s top 200 have been on the chart: 246 Average number of steams of weeks this week’s top 200: 2596081.98 Most common peak ranking of weeks this week’s top 200: 1 . For the data above, I used this link to make the date more readable. . Now, we did the same for the United Kingdom data. . # the days are the same so I won&#39;t redeclare them for i in days: avg_week_on_charts = 0 max_week_on_charts = 0 subset = weekly_gb_charts.loc[weekly_gb_charts[&#39;date&#39;] == i] avg_week_on_charts = subset[&#39;weeks_on_chart&#39;].mean() max_week_on_charts = subset[&#39;weeks_on_chart&#39;].max() avg_streams = subset[&#39;streams&#39;].mean() peak_ranking = subset[&#39;peak_rank&#39;].mode() ts = pd.to_datetime(str(i)) d = ts.strftime(&#39;%Y-%m-%d&#39;) print(&quot;Country: United Kingdom&quot;) print(&quot;Date: &quot;, d) print(&quot;Average number of weeks this week’s top 200 have been on the chart: &quot;, avg_week_on_charts) print(&quot;Maximum number of weeks this week’s top 200 have been on the chart: &quot;, max_week_on_charts) print(&quot;Average number of steams of weeks this week’s top 200: &quot;, avg_streams) print(&quot;Most common peak ranking of weeks this week’s top 200: &quot;, peak_ranking[0]) print(&quot;&quot;) . . Country: United Kingdom Date: 2021-01-07 Average number of weeks this week’s top 200 have been on the chart: 43.0 Maximum number of weeks this week’s top 200 have been on the chart: 211 Average number of steams of weeks this week’s top 200: 520903.335 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-01-14 Average number of weeks this week’s top 200 have been on the chart: 39.57 Maximum number of weeks this week’s top 200 have been on the chart: 212 Average number of steams of weeks this week’s top 200: 584180.265 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-01-21 Average number of weeks this week’s top 200 have been on the chart: 40.41 Maximum number of weeks this week’s top 200 have been on the chart: 213 Average number of steams of weeks this week’s top 200: 604862.895 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-01-28 Average number of weeks this week’s top 200 have been on the chart: 41.13 Maximum number of weeks this week’s top 200 have been on the chart: 214 Average number of steams of weeks this week’s top 200: 579693.765 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-02-04 Average number of weeks this week’s top 200 have been on the chart: 40.73 Maximum number of weeks this week’s top 200 have been on the chart: 215 Average number of steams of weeks this week’s top 200: 593448.265 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-02-11 Average number of weeks this week’s top 200 have been on the chart: 41.605 Maximum number of weeks this week’s top 200 have been on the chart: 216 Average number of steams of weeks this week’s top 200: 567391.66 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-02-18 Average number of weeks this week’s top 200 have been on the chart: 42.325 Maximum number of weeks this week’s top 200 have been on the chart: 217 Average number of steams of weeks this week’s top 200: 599181.875 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-02-25 Average number of weeks this week’s top 200 have been on the chart: 42.46 Maximum number of weeks this week’s top 200 have been on the chart: 218 Average number of steams of weeks this week’s top 200: 583010.325 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-03-04 Average number of weeks this week’s top 200 have been on the chart: 43.84 Maximum number of weeks this week’s top 200 have been on the chart: 219 Average number of steams of weeks this week’s top 200: 594749.87 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-03-11 Average number of weeks this week’s top 200 have been on the chart: 42.6 Maximum number of weeks this week’s top 200 have been on the chart: 220 Average number of steams of weeks this week’s top 200: 593512.615 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-03-18 Average number of weeks this week’s top 200 have been on the chart: 42.92 Maximum number of weeks this week’s top 200 have been on the chart: 221 Average number of steams of weeks this week’s top 200: 608408.905 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-03-25 Average number of weeks this week’s top 200 have been on the chart: 39.52 Maximum number of weeks this week’s top 200 have been on the chart: 222 Average number of steams of weeks this week’s top 200: 654324.3 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-04-01 Average number of weeks this week’s top 200 have been on the chart: 39.88 Maximum number of weeks this week’s top 200 have been on the chart: 223 Average number of steams of weeks this week’s top 200: 670823.335 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-04-08 Average number of weeks this week’s top 200 have been on the chart: 41.085 Maximum number of weeks this week’s top 200 have been on the chart: 224 Average number of steams of weeks this week’s top 200: 662317.085 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-04-15 Average number of weeks this week’s top 200 have been on the chart: 38.52 Maximum number of weeks this week’s top 200 have been on the chart: 225 Average number of steams of weeks this week’s top 200: 691477.61 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-04-22 Average number of weeks this week’s top 200 have been on the chart: 40.895 Maximum number of weeks this week’s top 200 have been on the chart: 226 Average number of steams of weeks this week’s top 200: 673004.815 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-04-29 Average number of weeks this week’s top 200 have been on the chart: 42.435 Maximum number of weeks this week’s top 200 have been on the chart: 227 Average number of steams of weeks this week’s top 200: 669390.28 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-05-06 Average number of weeks this week’s top 200 have been on the chart: 40.675 Maximum number of weeks this week’s top 200 have been on the chart: 228 Average number of steams of weeks this week’s top 200: 660677.32 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-05-13 Average number of weeks this week’s top 200 have been on the chart: 41.625 Maximum number of weeks this week’s top 200 have been on the chart: 229 Average number of steams of weeks this week’s top 200: 652114.1 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-05-20 Average number of weeks this week’s top 200 have been on the chart: 39.3 Maximum number of weeks this week’s top 200 have been on the chart: 230 Average number of steams of weeks this week’s top 200: 708307.355 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-05-27 Average number of weeks this week’s top 200 have been on the chart: 37.54 Maximum number of weeks this week’s top 200 have been on the chart: 231 Average number of steams of weeks this week’s top 200: 749079.8 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-06-03 Average number of weeks this week’s top 200 have been on the chart: 41.385 Maximum number of weeks this week’s top 200 have been on the chart: 232 Average number of steams of weeks this week’s top 200: 756798.955 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-06-10 Average number of weeks this week’s top 200 have been on the chart: 41.77 Maximum number of weeks this week’s top 200 have been on the chart: 233 Average number of steams of weeks this week’s top 200: 706743.64 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-06-17 Average number of weeks this week’s top 200 have been on the chart: 37.435 Maximum number of weeks this week’s top 200 have been on the chart: 234 Average number of steams of weeks this week’s top 200: 693970.335 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-06-24 Average number of weeks this week’s top 200 have been on the chart: 41.855 Maximum number of weeks this week’s top 200 have been on the chart: 235 Average number of steams of weeks this week’s top 200: 655271.27 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-07-01 Average number of weeks this week’s top 200 have been on the chart: 36.855 Maximum number of weeks this week’s top 200 have been on the chart: 236 Average number of steams of weeks this week’s top 200: 706408.985 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-07-08 Average number of weeks this week’s top 200 have been on the chart: 38.32 Maximum number of weeks this week’s top 200 have been on the chart: 237 Average number of steams of weeks this week’s top 200: 683264.44 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-07-15 Average number of weeks this week’s top 200 have been on the chart: 40.95 Maximum number of weeks this week’s top 200 have been on the chart: 238 Average number of steams of weeks this week’s top 200: 704375.355 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-07-22 Average number of weeks this week’s top 200 have been on the chart: 37.53 Maximum number of weeks this week’s top 200 have been on the chart: 239 Average number of steams of weeks this week’s top 200: 746408.665 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-07-29 Average number of weeks this week’s top 200 have been on the chart: 39.92 Maximum number of weeks this week’s top 200 have been on the chart: 240 Average number of steams of weeks this week’s top 200: 761303.905 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-08-05 Average number of weeks this week’s top 200 have been on the chart: 37.605 Maximum number of weeks this week’s top 200 have been on the chart: 241 Average number of steams of weeks this week’s top 200: 701179.22 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-08-12 Average number of weeks this week’s top 200 have been on the chart: 40.615 Maximum number of weeks this week’s top 200 have been on the chart: 242 Average number of steams of weeks this week’s top 200: 654305.945 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-08-19 Average number of weeks this week’s top 200 have been on the chart: 42.015 Maximum number of weeks this week’s top 200 have been on the chart: 243 Average number of steams of weeks this week’s top 200: 645316.69 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-08-26 Average number of weeks this week’s top 200 have been on the chart: 43.135 Maximum number of weeks this week’s top 200 have been on the chart: 244 Average number of steams of weeks this week’s top 200: 643850.625 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-09-02 Average number of weeks this week’s top 200 have been on the chart: 39.14 Maximum number of weeks this week’s top 200 have been on the chart: 245 Average number of steams of weeks this week’s top 200: 679986.145 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-09-09 Average number of weeks this week’s top 200 have been on the chart: 35.025 Maximum number of weeks this week’s top 200 have been on the chart: 246 Average number of steams of weeks this week’s top 200: 806664.305 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-09-16 Average number of weeks this week’s top 200 have been on the chart: 38.71 Maximum number of weeks this week’s top 200 have been on the chart: 247 Average number of steams of weeks this week’s top 200: 677254.66 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-09-23 Average number of weeks this week’s top 200 have been on the chart: 38.94 Maximum number of weeks this week’s top 200 have been on the chart: 248 Average number of steams of weeks this week’s top 200: 678603.255 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-09-30 Average number of weeks this week’s top 200 have been on the chart: 42.975 Maximum number of weeks this week’s top 200 have been on the chart: 249 Average number of steams of weeks this week’s top 200: 637718.84 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-10-07 Average number of weeks this week’s top 200 have been on the chart: 43.485 Maximum number of weeks this week’s top 200 have been on the chart: 250 Average number of steams of weeks this week’s top 200: 619664.76 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-10-14 Average number of weeks this week’s top 200 have been on the chart: 42.355 Maximum number of weeks this week’s top 200 have been on the chart: 251 Average number of steams of weeks this week’s top 200: 635819.805 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-10-21 Average number of weeks this week’s top 200 have been on the chart: 38.96 Maximum number of weeks this week’s top 200 have been on the chart: 252 Average number of steams of weeks this week’s top 200: 719046.185 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-10-28 Average number of weeks this week’s top 200 have been on the chart: 41.25 Maximum number of weeks this week’s top 200 have been on the chart: 253 Average number of steams of weeks this week’s top 200: 666411.66 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-11-04 Average number of weeks this week’s top 200 have been on the chart: 36.425 Maximum number of weeks this week’s top 200 have been on the chart: 254 Average number of steams of weeks this week’s top 200: 673638.05 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-11-11 Average number of weeks this week’s top 200 have been on the chart: 34.5 Maximum number of weeks this week’s top 200 have been on the chart: 255 Average number of steams of weeks this week’s top 200: 662097.715 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-11-18 Average number of weeks this week’s top 200 have been on the chart: 25.71 Maximum number of weeks this week’s top 200 have been on the chart: 256 Average number of steams of weeks this week’s top 200: 717145.115 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-11-25 Average number of weeks this week’s top 200 have been on the chart: 27.905 Maximum number of weeks this week’s top 200 have been on the chart: 257 Average number of steams of weeks this week’s top 200: 789503.38 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-12-02 Average number of weeks this week’s top 200 have been on the chart: 31.34 Maximum number of weeks this week’s top 200 have been on the chart: 258 Average number of steams of weeks this week’s top 200: 769239.105 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-12-09 Average number of weeks this week’s top 200 have been on the chart: 28.505 Maximum number of weeks this week’s top 200 have been on the chart: 259 Average number of steams of weeks this week’s top 200: 856353.93 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-12-16 Average number of weeks this week’s top 200 have been on the chart: 27.18 Maximum number of weeks this week’s top 200 have been on the chart: 260 Average number of steams of weeks this week’s top 200: 881728.265 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-12-23 Average number of weeks this week’s top 200 have been on the chart: 27.315 Maximum number of weeks this week’s top 200 have been on the chart: 261 Average number of steams of weeks this week’s top 200: 1007787.465 Most common peak ranking of weeks this week’s top 200: 1 Country: United Kingdom Date: 2021-12-30 Average number of weeks this week’s top 200 have been on the chart: 26.675 Maximum number of weeks this week’s top 200 have been on the chart: 262 Average number of steams of weeks this week’s top 200: 973166.68 Most common peak ranking of weeks this week’s top 200: 1 . Then we looked at the streams for the number 1 song each week and plotted it for both the US and the UK, just to see what the trends looked like. . number1us = weekly_us_charts.loc[weekly_us_charts[&#39;rank&#39;] == 1] . number1uk = weekly_gb_charts.loc[weekly_gb_charts[&#39;rank&#39;] == 1] . number1us.plot(kind=&#39;bar&#39;, x=&#39;date&#39;, y=&#39;streams&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;date&#39;&gt; . number1uk.plot(kind=&#39;bar&#39;, x=&#39;date&#39;, y=&#39;streams&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;date&#39;&gt; . We also wanted to plot the current rank compared with the previous rank for one week. We picked the day at random (2021-11-18) and plotted it for both the US and UK. . peakprevUS = weekly_us_charts.loc[weekly_us_charts[&#39;date&#39;] == &quot;2021-11-18T00:00:00.000000000&quot;] peakprevUS.head() . . rank uri artist_names track_name source peak_rank previous_rank weeks_on_chart streams date . 0 1 | spotify:track:5enxwA8aAbwZbf5qCHORXi | Taylor Swift | All Too Well (10 Minute Version) (Taylor&#39;s Ver... | Taylor Swift | 1 | -1 | 1 | 18105602 | 2021-11-18 | . 1 2 | spotify:track:7sMBvZCSUl99bJLXZaLa0b | Bruno Mars, Anderson .Paak, Silk Sonic | Smokin Out The Window | Aftermath Entertainment/Atlantic | 2 | 5 | 2 | 10067882 | 2021-11-18 | . 2 3 | spotify:track:4OAuvHryIVv4kMDNSLuPt6 | Taylor Swift | Red (Taylor&#39;s Version) | Taylor Swift | 3 | -1 | 1 | 8676447 | 2021-11-18 | . 3 4 | spotify:track:3nsfB1vus2qaloUdcBZvDu | Taylor Swift | All Too Well (Taylor&#39;s Version) | Taylor Swift | 4 | -1 | 1 | 8403008 | 2021-11-18 | . 4 5 | spotify:track:01K4zKU104LyJ8gMb7227B | Taylor Swift, Phoebe Bridgers | Nothing New (feat. Phoebe Bridgers) (Taylor’s ... | Taylor Swift | 5 | -1 | 1 | 7818397 | 2021-11-18 | . We want to filter out the ones that have -1 as a ranking, which means they probably weren&#39;t on the ranking before, and then plot it. . X = peakprevfiltUS[&quot;rank&quot;] y = peakprevfiltUS[&quot;previous_rank&quot;] theta = numpy.polyfit(X, y, 1) y_line = theta[1] + theta[0] * X plt.scatter(X, y) plt.plot(X, y_line, &#39;r&#39;) plt.show() . . peakprevUK = weekly_gb_charts.loc[weekly_gb_charts[&#39;date&#39;] == &quot;2021-11-18T00:00:00.000000000&quot;] peakprevUK.head() . rank uri artist_names track_name source peak_rank previous_rank weeks_on_chart streams date . 0 1 | spotify:track:0gplL1WMoJ6iYaPgMCL0gX | Adele | Easy On Me | Columbia | 1 | 1 | 5 | 3458623 | 2021-11-18 | . 1 2 | spotify:track:5enxwA8aAbwZbf5qCHORXi | Taylor Swift | All Too Well (10 Minute Version) (Taylor&#39;s Ver... | Taylor Swift | 2 | -1 | 1 | 2787198 | 2021-11-18 | . 2 3 | spotify:track:50nfwKoDiSYg8zOCREWAm5 | Ed Sheeran | Shivers | Atlantic Records UK | 1 | 2 | 10 | 2616693 | 2021-11-18 | . 3 4 | spotify:track:7rglLriMNBPAyuJOMGwi39 | Elton John, Dua Lipa, PNAU | Cold Heart - PNAU Remix | EMI | 2 | 4 | 14 | 2237196 | 2021-11-18 | . 4 5 | spotify:track:2BzAGK3lEZAQz5cU0Ae1wd | ArrDee | Flowers (Say My Name) | Universal-Island Records Ltd. | 5 | 5 | 2 | 2139786 | 2021-11-18 | . X = peakprevfiltUK[&quot;rank&quot;] y = peakprevfiltUK[&quot;previous_rank&quot;] theta = numpy.polyfit(X, y, 1) y_line = theta[1] + theta[0] * X plt.scatter(X, y) plt.plot(X, y_line, &#39;r&#39;) plt.show() . . After this preliminary research, we determined that we wanted to look at 2 artists for our research question: Adele, who is from the UK, and Lil Nas X, who is from the US. So we did a little bit more exploratory analysis into these two artists. . Interestingly already, we see a bit of a difference! In the year 2021, Lil Nas X (US) was on the weekly Top 200 charts in the US 88 times, while he was on the weekly Top 200 charts in UK for a fewer number of times 78. For Adele, she was on the US charts 73 times but on the UK ones 168 times. . For both of these artists, we also wanted to look at the songs that appeared on the charts. . array([&#39;HOLIDAY&#39;, &#39;MONTERO (Call Me By Your Name)&#39;, &#39;SUN GOES DOWN&#39;, &#39;INDUSTRY BABY (feat. Jack Harlow)&#39;, &#39;THATS WHAT I WANT&#39;, &#39;SCOOP (feat. Doja Cat)&#39;, &#39;DOLLA SIGN SLIME (feat. Megan Thee Stallion)&#39;, &#39;DEAD RIGHT NOW&#39;, &#39;TALES OF DOMINICA&#39;, &#39;LOST IN THE CITADEL&#39;, &#39;ONE OF ME (feat. Elton John)&#39;, &#39;AM I DREAMING (feat. Miley Cyrus)&#39;, &#39;DONT WANT IT&#39;, &#39;VOID&#39;, &#39;LIFE AFTER SALEM&#39;], dtype=object) . array([&#39;HOLIDAY&#39;, &#39;MONTERO (Call Me By Your Name)&#39;, &#39;SUN GOES DOWN&#39;, &#39;INDUSTRY BABY (feat. Jack Harlow)&#39;, &#39;THATS WHAT I WANT&#39;, &#39;SCOOP (feat. Doja Cat)&#39;, &#39;DEAD RIGHT NOW&#39;, &#39;DOLLA SIGN SLIME (feat. Megan Thee Stallion)&#39;, &#39;TALES OF DOMINICA&#39;, &#39;LOST IN THE CITADEL&#39;, &#39;ONE OF ME (feat. Elton John)&#39;, &#39;DONT WANT IT&#39;, &#39;AM I DREAMING (feat. Miley Cyrus)&#39;, &#39;VOID&#39;], dtype=object) . array([&#39;When We Were Young&#39;, &#39;Easy On Me&#39;, &#39;Someone Like You&#39;, &#39;Rolling in the Deep&#39;, &#39;Love In The Dark&#39;, &#39;Set Fire to the Rain&#39;, &#39;All I Ask&#39;, &#39;Chasing Pavements&#39;, &#39;Send My Love (To Your New Lover)&#39;, &#39;Make You Feel My Love&#39;, &#39;Hello&#39;, &#39;Oh My God&#39;, &#39;Can I Get It&#39;, &#39;My Little Love&#39;, &#39;I Drink Wine&#39;, &#39;Strangers By Nature&#39;, &#39;Cry Your Heart Out&#39;, &#39;To Be Loved&#39;, &#39;All Night Parking (with Erroll Garner) Interlude&#39;, &#39;Woman Like Me&#39;, &#39;Hold On&#39;, &#39;Love Is A Game&#39;], dtype=object) . array([&#39;Someone Like You&#39;, &#39;Make You Feel My Love&#39;, &#39;Rolling in the Deep&#39;, &#39;When We Were Young&#39;, &#39;Love In The Dark&#39;, &#39;Chasing Pavements&#39;, &#39;Set Fire to the Rain&#39;, &#39;Send My Love (To Your New Lover)&#39;, &#39;Rumour Has It&#39;, &#39;All I Ask&#39;, &#39;Skyfall&#39;, &#39;Hello&#39;, &#39;Easy On Me&#39;, &#39;Turning Tables&#39;, &#39;Water Under the Bridge&#39;, &#39;Hometown Glory&#39;, &#39;Remedy&#39;, &#39;Oh My God&#39;, &#39;I Drink Wine&#39;, &#39;My Little Love&#39;, &#39;Can I Get It&#39;, &#39;Strangers By Nature&#39;, &#39;Cry Your Heart Out&#39;, &#39;To Be Loved&#39;, &#39;Hold On&#39;, &#39;All Night Parking (with Erroll Garner) Interlude&#39;, &#39;Woman Like Me&#39;, &#39;Love Is A Game&#39;], dtype=object) . # Find songs in one list that aren&#39;t on the other lilnasxUKsongs = lilnasxUK[&#39;track_name&#39;].unique() lilnasxUSsongs = lilnasxUS[&#39;track_name&#39;].unique() for song in lilnasxUSsongs: if song not in lilnasxUKsongs: print(&quot;The song &quot; + song + &quot; is in the US charts but not the UK charts&quot;) for songs in lilnasxUKsongs: if songs not in lilnasxUSsongs: print(&quot;The song &quot; + songs + &quot; is in the UK charts but not the US charts&quot;) . . The song LIFE AFTER SALEM is in the US charts but not the UK charts . # Find songs in one list that aren&#39;t on the other adeleUKsongs = adeleUK[&#39;track_name&#39;].unique() adeleUSsongs = adeleUS[&#39;track_name&#39;].unique() for song in adeleUSsongs: if song not in adeleUKsongs: print(&quot;The song &quot; + song + &quot; is in the US charts but not the UK charts&quot;) for songs in adeleUKsongs: if songs not in adeleUSsongs: print(&quot;The song &quot; + songs + &quot; is in the UK charts but not the US charts&quot;) . . The song Rumour Has It is in the UK charts but not the US charts The song Skyfall is in the UK charts but not the US charts The song Turning Tables is in the UK charts but not the US charts The song Water Under the Bridge is in the UK charts but not the US charts The song Hometown Glory is in the UK charts but not the US charts The song Remedy is in the UK charts but not the US charts . We then wanted to see the rankings of each of the songs for each of the artists in plot form . Rankings for Lil Nas X songs in US . &lt;AxesSubplot:xlabel=&#39;track_name&#39;&gt; . . &lt;AxesSubplot:xlabel=&#39;track_name&#39;&gt; . We want to plot the ranks of the songs in each country for both Lil Nas X and Adele. . Rankings for Lil Nas X songs in US (scatterplot and by date) . lilnasxUS.plot(kind=&#39;scatter&#39;, x=&#39;date&#39;, y=&#39;rank&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;date&#39;, ylabel=&#39;rank&#39;&gt; . Rankings for Lil Nas X songs in UK (scatterplot and by date) . lilnasxUK.plot(kind=&#39;scatter&#39;, x=&#39;date&#39;, y=&#39;rank&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;date&#39;, ylabel=&#39;rank&#39;&gt; . Rankings for Adele songs in US (scatterplot and by date) . adeleUS.plot(kind=&#39;scatter&#39;, x=&#39;date&#39;, y=&#39;rank&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;date&#39;, ylabel=&#39;rank&#39;&gt; . Rankings for Adele songs in UK (scatterplot and by date) . adeleUK.plot(kind=&#39;scatter&#39;, x=&#39;date&#39;, y=&#39;rank&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;date&#39;, ylabel=&#39;rank&#39;&gt; . Results . As we can see from above, a preliminary analysis of the data showed some interesting trends. . First, doing a preliminary analysis of the data by looking at streams of the Top 200 Hits for each week for eacch country in the year 2021 showed that people in the US streamed quite a bit more than people in the UK. While the maximum number of streams we say in the US was 3*10^7, the maximum that we saw in the UK was 10^7. . We also did a short analysis on the ranking of the ranks for a certain day versus the previous rank that it held. While we found that most of them held the same ranking as the week before (ie, lots of points fell along the x=y line), there were visually apparent differences between the US and UK graphs. For the US scatter plot, a lot of the points that didn&#39;t fall near the x=y line were towards the songs with the most ranking, while in the UK it seemed like there were points along the smaller rankings as well that didn&#39;t fall close to that line. We thought that was interesting, since the songs with the lowest rankings are ones that are the most frequently listened to/usually stayed ranked higher. . In order to answer our research question, we examined the ranks of two artists: Lil Nas X, who is from the US, and Adele, who is from the UK. The first goal of our data exploration was to see if the origin country of an artist affects their presence on the weekly Top 200 Hits list. . The first analysis we did was a simple one -- checking to see how many times each artists&#39;s songs showed up in the weekly charts for each country (note: we also counted if a song showed up on the charts multiple times in the same day). We immediately saw that in the year 2021, Lil Nas X (US) was on the weekly Top 200 charts in the US 88 times, while he was on the weekly Top 200 charts in UK for a fewer number of times 78. For Adele, she was on the US charts 73 times but on the UK ones 168 times, which is considerably more. So it seems that the country that an artist is from is slightly correlated with their frequency on the charts. . Next, we wanted to see if more songs were listened to by Spotify users of the same country as the artist. So we went through to see which Lil Nas X songs were listened to by US listeners but not UK listeners, and which Adele songs were listened to by UK listeners but not US listeners. We found that: . For Lil Nas X: . The song LIFE AFTER SALEM is in the US charts but not the UK charts | . For Adele: . The song Rumour Has It is in the UK charts but not the US charts | The song Skyfall is in the UK charts but not the US charts | The song Turning Tables is in the UK charts but not the US charts | The song Water Under the Bridge is in the UK charts but not the US charts | The song Hometown Glory is in the UK charts but not the US charts | The song Remedy is in the UK charts but not the US charts | . In this way, we found that the listeners might listen to more songs from an album (therefore giving the songs a higher ranking) if the artist they are listening to is from their country. . Then, we wanted to see the rankings of each of the songs for Lil Nas X in plot form. We didn&#39;t see many surprising results here, as we saw drop off of rankings of songs similarly for Lil Nas X in the US and the UK. (The bar chart looks very similar). . Afterward, we wanted to compare the ranks of the songs in each country for each of the artists as compared to the days that they were on the Top 200 Chart. This analysis also produced interesting results, as we found similar rankings of Lil Nas X&#39;s songs in both the US and UK (visually, it seems that Lil Nas X&#39;s rankings were slightly lower in the US during that time, but it&#39;s a fairly small difference that we didn&#39;t feel like we could make a strong conclusion about it), but Adele had songs that were popular in the UK earlier on during the year that weren&#39;t on the charts in the US (during Jan 2021 - October 2021) (examining the Y scales of both the scatterplots for Adele). This analysis of ranking as compared to the dates showed us that the country that an artist is from is slightly correlated with their ranking and frequency on the charts. . Map Analysis . import geopandas as gpd . /opt/conda/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow. warnings.warn( . def plotmaps(df1, df2, artist): for date in df1.index: if date in df1.index and date in df2.index: d = {&#39;rank&#39;: [df1.loc[date][&quot;rank&quot;], df2.loc[date][&quot;rank&quot;]], &#39;iso_a3&#39;: [df1.loc[date][&quot;iso_a3&quot;], df2.loc[date][&quot;iso_a3&quot;]]} df = pd.DataFrame(data=d) # plt.subplot(1, 2, 1) table = countries.merge(df, how=&quot;left&quot;, left_on=[&#39;iso_a3&#39;], right_on=[&#39;iso_a3&#39;]) table.plot(column=&quot;rank&quot;, cmap=&quot;viridis&quot;,legend=True) plt.title(date.strftime(&#39;%b-%Y&#39;) + &quot; &quot; + artist + &quot; Mean Rank (relative)&quot;) . Lil Nas X Map Plots of Average Ranking . Color Map plots of US and UK&#39;s average ranking for all Lil Nas X songs. . Initial Map analysis . Above are monthly graphs of the rankings of the songs for both US and UK. You can see that the regions are colored by the average ranking of the artist Lil Nas X. The darker purple is indicative of a smaller rank number, which means that the song is charting better. . These are the relative rankings of Lil Nas X. Relative rankings mean that the legend is bounded by both the country&#39;s min and max ranking, and each map is only loosely related. These maps are best for examining the change between the US and UK ranking in respect to each other. . As you can see, in the beginning of the year, the UK is actually ranking Lil Nas X songs higher. But also looking at the ranges, the ranges are quite small- less than 10 ranks apart. . Some issues . There is some concern that since I am averaging ranks, if Lil Nas X has multiple charting songs, some lower charting songs can drag down the average rank of his songs- so he may be doing pretty well but we don&#39;t see it reflected. . We can rectify this in 2 ways- . We can look at the average rank of just one song | We can look at the stream ratio of his songs (overall Lil Nas X streams vs all streams on the top 200). | Let&#39;s start with the first solution. His hit song &quot;Industry Baby&quot; came out in July, and we will do lyrical analysis of this song, so what if we looked at only those times and the rank of that song? . Lil Nas X&#39;s Industry Baby Average Ranking Map plots- July/August only . Industry Baby was released July 23rd, 2021! . Map Analysis of Mean Ranking for INDUSTRY BABY . Looking at the just July and August maps, we can see that Lil Nas X&#39;s new song was doing the best in the US. We can see that it debuted to a high peak in the US, and stayed that high throughout the month after it was released. The UK was slower to catch up, as the UK&#39;s ranking of INDUSTRY BABY started lower at 14 and lowly climbed up to around 4. . This is a little different than the aggregate mean rankings from the first map graphs told us, suggesting that the mean rankings of multiple songs is misleading, as our analysis of just the mean rank of INDUSTRY BABY clearly shows that US is faster to highly rank Lil Nas X&#39;s songs, and also that the US keeps the rank higher for longer than the UK. . Now knowing that our initial way of analyzing mean rankings was incorrect, let&#39;s instead use the stream ratio (# of Lil Nas X streams/ total streams) to graph. . Map Analysis of Monthly Stream Ratio for Lil Nas X . Lil Nas X Monthly Stream Ratio in the US and UK in 2021 . When looking at the Monthly stream ratio, we can see that there is still a clear switch between the UK&#39;s love for Lil Nas X over other artists, and the US&#39;s. . Remember in this graph, the higher the stream ratio, the more Lil Nas X songs are listened to- the color yellow is indicative of a greater stream ratio, and purple of a lower. . So we can see that in the begining, the UK is leading with how much Lil Nas X they&#39;re listening to, and the margins are slim- to the 3rd decimal place. Around when Lil Nas X had a 2021 release, early March, we can still see that UK charts are still leading in their listening of Lil Nas X. . It&#39;s only when Lil Nas X&#39;s most popular singles release, through May to the end of the year, where the US takes the lead, and a larger lead (The US stream ratio is around 1.5xs greater than the UK in some months) in months following releases. Such as August, following the INDUSTRY BABY release, and October, following the release of THAT&#39;S WHAT I WANT and his album in September . Now let&#39;s move on to Adele! . Adele&#39;s Maps . Adele Monthly Stream Ratio in the US and UK in 2021 . The analysis of this is much easier- Adele was not that popular in the US, so she only charted 3 months in the US. . And we can see that UK is winning every month- Adele is clearly much more popular in the UK, but the peak timing is quite similar, so both the UK and US were able to pick up streaming Adele&#39;s new music released in November (the peak of her stream ratio) around the same time. The UK remains a high stream ratio lead to the US as well, almost doubling the stream ratio of the US&#39;s every month. . Looking at Easy On Me . Released October 15th, 2021 . Looking at only Easy On Me, we can see it was a clear instant hit. But it was a hit longer in the UK, Adele&#39;s home country, as the US allows Easy On Me&#39;s rank to drop in mid-November. . Map Analysis overall results . Seems like there is a clear correlation between the Artist&#39;s country of origin and their popularity in each country. There is also a quicker onset of popularity for the artist in their own origin country, seen through our deeper analysis of weekly rankings of INDUSTRY BABY after its release in the US and UK. . Lyrical Analysis . import csv . Note: We replaced the profanity in the lyrics before uploading the csv file. . file = open(&#39;Data/lilnasx_industrybaby.csv&#39;) . csvreader = csv.reader(file) . rows = [] for row in csvreader: rows += row #rows . import nltk nltk.download(&#39;punkt&#39;) . [nltk_data] Downloading package punkt to /home/jovyan/nltk_data... [nltk_data] Unzipping tokenizers/punkt.zip. . True . from nltk.tokenize import word_tokenize, sent_tokenize . words = [] for s in rows: for w in word_tokenize(s): words.append(w) . print(words[:20]) . [&#39;Baby&#39;, &#39;back&#39;, &#39;ayy&#39;, &#39;Couple&#39;, &#39;racks&#39;, &#39;,&#39;, &#39;ayy&#39;, &#39;Couple&#39;, &#39;Grammys&#39;, &#39;on&#39;, &#39;him&#39;, &#39;Couple&#39;, &#39;plaques&#39;, &#39;,&#39;, &#39;ayy&#39;, &#39;That&#39;, &#34;&#39;s&#34;, &#39;a&#39;, &#39;fact&#39;, &#39;,&#39;] . The built in word tokenizer didn&#39;t work because it splits words with apostrophes, so we built our own. . lyricwords = [] for row in rows: words = row.split(&quot; &quot;) for word in words: if word[0] == &quot;(&quot; and word[-1] == &quot;,&quot;: newword = word[1:] newword = newword[:len(newword)-1] lyricwords += [newword] elif word[-1] == &#39;,&#39;: newword = word[:len(word)-1] lyricwords += [newword] elif word[0] == &quot;(&quot; and word[-1] == &quot;)&quot;: newword = word[1:] newword = newword[:len(newword)-1] lyricwords += [newword] elif word[0] == &quot;(&quot;: newword = word[1:] lyricwords += [newword] elif word[-1] == &quot;)&quot;: newword = word[:len(word)-1] lyricwords += [newword] else: lyricwords += [word] #print(lyricwords) . wordsLower = [each_string.lower() for each_string in lyricwords] #wordsLower . stopwords = [&quot;the&quot;] lyricsNoThe = [w for w in wordsLower if w not in stopwords] . from nltk.probability import FreqDist . freq = FreqDist(lyricsNoThe) #freq . for i in sorted(freq, key=freq.get, reverse=True)[:20]: print(i,freq[i]) . i 38 yeah 13 you 13 i&#39;m 12 like 11 for 10 ain&#39;t 10 me 10 ayy 9 they 9 don&#39;t 9 it 8 from 8 get 8 tell 8 back 7 is 7 got 7 your 7 &#39;em 7 . import nltk from nltk.sentiment import vader nltk.download(&#39;vader_lexicon&#39;) . [nltk_data] Downloading package vader_lexicon to [nltk_data] /home/jovyan/nltk_data... [nltk_data] Package vader_lexicon is already up-to-date! . True . sia = vader.SentimentIntensityAnalyzer() . for line in rows: print(line) print(sia.polarity_scores(line)) . Baby back ayy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Couple racks, ayy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Couple Grammys on him {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Couple plaques, ayy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} That&#39;s a fact, ayy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Throw it back, ayy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Throw it back, ayy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} And this one is for the champions {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.638, &#39;pos&#39;: 0.362, &#39;compound&#39;: 0.5267} I ain&#39;t lost since I began, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.419, &#39;pos&#39;: 0.581, &#39;compound&#39;: 0.4874} Funny how you said it was the end, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.579, &#39;pos&#39;: 0.421, &#39;compound&#39;: 0.6249} Then I went did it again, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.694, &#39;pos&#39;: 0.306, &#39;compound&#39;: 0.296} I told you long ago, on the road {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I got what they waitin&#39; for {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I don&#39;t run from nothin&#39;, dog {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Get your soldiers, tell &#39;em I ain&#39;t layin&#39; low {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.794, &#39;pos&#39;: 0.206, &#39;compound&#39;: 0.2057} You was never really rootin&#39; for me anyway {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} When I&#39;m back up at the top I wanna hear you say {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.847, &#39;pos&#39;: 0.153, &#39;compound&#39;: 0.2023} He don&#39;t run from nothin&#39;, dog {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Get your soldiers, tell &#39;em that the break is over {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Uh, need to, uh {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Need to get this album done {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Need a couple number ones {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.698, &#39;pos&#39;: 0.302, &#39;compound&#39;: 0.0772} Need a plaque on every song {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Need me like one with Nicki now {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.706, &#39;pos&#39;: 0.294, &#39;compound&#39;: 0.3612} Tell a rap n-, I don&#39;t see ya, ha {&#39;neg&#39;: 0.253, &#39;neu&#39;: 0.747, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.2584} I am a pop n- like Bieber, ha {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.449, &#39;pos&#39;: 0.551, &#39;compound&#39;: 0.5994} I don&#39;t fuck b-, I&#39;m queer, ha {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.432, &#39;pos&#39;: 0.568, &#39;compound&#39;: 0.6428} But these n- b- like Madea {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.606, &#39;pos&#39;: 0.394, &#39;compound&#39;: 0.5023} Yeah, yeah, yeah (yeah) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.132, &#39;pos&#39;: 0.868, &#39;compound&#39;: 0.6808} Ayy, oh, let&#39;s do it {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I ain&#39;t fall off, I just ain&#39;t release my new shit {&#39;neg&#39;: 0.31, &#39;neu&#39;: 0.69, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5574} I blew up now everybody tryna sue me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} You call me Nas, but the hood call me Doobie, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.781, &#39;pos&#39;: 0.219, &#39;compound&#39;: 0.4215} And this one is for the champions {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.638, &#39;pos&#39;: 0.362, &#39;compound&#39;: 0.5267} I ain&#39;t lost since I began, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.419, &#39;pos&#39;: 0.581, &#39;compound&#39;: 0.4874} Funny how you said it was the end, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.579, &#39;pos&#39;: 0.421, &#39;compound&#39;: 0.6249} Then I went did it again, yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.694, &#39;pos&#39;: 0.306, &#39;compound&#39;: 0.296} I told you long ago, on the road {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I got what they waitin&#39; for (I got what they waitin&#39; for) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I don&#39;t run from nothin&#39;, dog {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Get your soldiers, tell &#39;em I ain&#39;t layin&#39; low {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.794, &#39;pos&#39;: 0.206, &#39;compound&#39;: 0.2057} (B-, I ain&#39;t runnin&#39; from no one) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.726, &#39;pos&#39;: 0.274, &#39;compound&#39;: 0.2235} You was never really rootin&#39; for me anyway (like, ooh-ooh) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} When I&#39;m back up at the top I wanna hear you say (like, ooh-ooh) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.87, &#39;pos&#39;: 0.13, &#39;compound&#39;: 0.2023} He don&#39;t run from nothin&#39;, dog {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Get your soldiers, tell &#39;em that the break is over {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} My track record so clean {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.534, &#39;pos&#39;: 0.466, &#39;compound&#39;: 0.541} They couldn&#39;t wait to just bash me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I must be gettin&#39; too flashy {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Y&#39;all shouldn&#39;t have let the world gas me (woo) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} It&#39;s too late &#39;cause I&#39;m here to stay {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} And these girls know that I&#39;m nasty (mm) {&#39;neg&#39;: 0.34, &#39;neu&#39;: 0.66, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5574} I sent her back to her boyfriend {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} With my handprint on her ass cheek {&#39;neg&#39;: 0.368, &#39;neu&#39;: 0.632, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5423} City talkin&#39;, we takin&#39; notes {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Tell &#39;em all to keep makin&#39; posts {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Wish he could but he can&#39;t get close {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.791, &#39;pos&#39;: 0.209, &#39;compound&#39;: 0.2144} OG so proud of me that he chokin&#39; up while he makin&#39; toasts {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.78, &#39;pos&#39;: 0.22, &#39;compound&#39;: 0.5256} I&#39;m the type that you can&#39;t control {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Said I would then I made it so (so) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I don&#39;t clear up rumors (ayy) {&#39;neg&#39;: 0.353, &#39;neu&#39;: 0.647, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.2924} Where&#39;s y&#39;all sense of humor? (Ayy) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.704, &#39;pos&#39;: 0.296, &#39;compound&#39;: 0.2732} I&#39;m done makin&#39; jokes &#39;cause they got old like baby boomers {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.667, &#39;pos&#39;: 0.333, &#39;compound&#39;: 0.5423} Turn my haters to consumers {&#39;neg&#39;: 0.444, &#39;neu&#39;: 0.556, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.4939} I make vets feel like they juniors (juniors) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.706, &#39;pos&#39;: 0.294, &#39;compound&#39;: 0.3612} Say your time is comin&#39; soon but just like Oklahoma (mm) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.755, &#39;pos&#39;: 0.245, &#39;compound&#39;: 0.5023} Mine is comin&#39; sooner (mm) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I&#39;m just a late bloomer (mm) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I didn&#39;t peak in high school, I&#39;m still out here gettin&#39; cuter (woo) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.769, &#39;pos&#39;: 0.231, &#39;compound&#39;: 0.5106} All these social networks and computers {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Got these p- walkin&#39; &#39;round like they ain&#39;t losers (losers) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.603, &#39;pos&#39;: 0.397, &#39;compound&#39;: 0.6458} I told you long ago, on the road {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I got what they waitin&#39; for (I got what they waitin&#39; for) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I don&#39;t run from nothin&#39;, dog {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Get your soldiers, tell &#39;em I ain&#39;t layin&#39; low {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.794, &#39;pos&#39;: 0.206, &#39;compound&#39;: 0.2057} (B-, I ain&#39;t runnin&#39; from no one) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.726, &#39;pos&#39;: 0.274, &#39;compound&#39;: 0.2235} You was never really rootin&#39; for me anyway (like, ooh-ooh) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} When I&#39;m back up at the top I wanna hear you say (like, ooh-ooh) {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.87, &#39;pos&#39;: 0.13, &#39;compound&#39;: 0.2023} He don&#39;t run from nothin&#39;, dog {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Get your soldiers, tell &#39;em that the break is over {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.0, &#39;pos&#39;: 1.0, &#39;compound&#39;: 0.296} I&#39;m the industry baby, mm {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I&#39;m the industry baby {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Yeah {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.0, &#39;pos&#39;: 1.0, &#39;compound&#39;: 0.296} . Overall, Lil Nas X&#39;s song, &quot;Industry Baby&quot; had mostly neutral to positive polarity scores. The song talks about his accomplishments as well as demonstrates his empowerment over addressing his &#39;haters.&#39; The frequency distribution of his lyrics illustrate that the song is about himself and others as &quot;I&quot;, &quot;you&quot;, &quot;me&quot;, &quot;they&quot; are among the top of his most used lyrics. . file2 = open(&#39;Data/adele_easyonme.csv&#39;) . csvreader2 = csv.reader(file2) . rows2 = [] for row2 in csvreader2: rows2 += row2 #rows2 . lyricwords2 = [] for row in rows2: words2 = row.split(&quot; &quot;) for word2 in words2: if word2[0] == &quot;(&quot; and word2[-1] == &quot;,&quot;: newword2 = word2[1:] newword2 = newword2[:len(newword2)-1] lyricwords2 += [newword2] elif word2[-1] == &#39;,&#39;: newword2 = word2[:len(word2)-1] lyricwords2 += [newword2] elif word2[0] == &quot;(&quot; and word2[-1] == &quot;)&quot;: newword2 = word2[1:] newword2 = newword2[:len(newword2)-1] lyricwords2 += [newword2] elif word2[0] == &quot;(&quot;: newword2 = word2[1:] lyricwords2 += [newword2] elif word2[-1] == &quot;)&quot;: newword2 = word2[:len(word2)-1] lyricwords2 += [newword2] else: lyricwords2 += [word2] #print(lyricwords2) . wordsLower2 = [each_string.lower() for each_string in lyricwords2] #wordsLower2 . stopwords = [&quot;the&quot;] lyricsNoThe2 = [w for w in wordsLower2 if w not in stopwords] . . freq2 = FreqDist(lyricsNoThe2) #freq2 . for i in sorted(freq2, key=freq2.get, reverse=True)[:20]: print(i,freq2[i]) . i 18 to 12 me 10 in 6 go 6 easy 6 on 6 no 5 baby 4 was 4 had 4 so 4 there 3 but 3 still 3 a 3 child 3 didn&#39;t 3 get 3 chance 3 . for line2 in rows2: print(line2) print(sia.polarity_scores(line2)) . There ain&#39;t no gold in this river {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.761, &#39;pos&#39;: 0.239, &#39;compound&#39;: 0.2235} That I&#39;ve been washin&#39; my hands in forever {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I know there is hope in these waters {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.674, &#39;pos&#39;: 0.326, &#39;compound&#39;: 0.4404} But I can&#39;t bring myself to swim {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} When I am drowning in this silence {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Baby, let me in {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Go easy on me, baby {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.58, &#39;pos&#39;: 0.42, &#39;compound&#39;: 0.4404} I was still a child {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Didn&#39;t get the chance to {&#39;neg&#39;: 0.303, &#39;neu&#39;: 0.697, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.1877} Feel the world around me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I had no time to choose {&#39;neg&#39;: 0.355, &#39;neu&#39;: 0.645, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.296} What I chose to do {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} So go easy on me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.557, &#39;pos&#39;: 0.443, &#39;compound&#39;: 0.4902} There ain&#39;t no room for things to change {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.788, &#39;pos&#39;: 0.212, &#39;compound&#39;: 0.2235} When we are both so deeply stuck in our ways {&#39;neg&#39;: 0.222, &#39;neu&#39;: 0.778, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.376} You can&#39;t deny how hard I have tried {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.6, &#39;pos&#39;: 0.4, &#39;compound&#39;: 0.3252} I changed who I was to put you both first {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} But now I give up {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Go easy on me, baby {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.58, &#39;pos&#39;: 0.42, &#39;compound&#39;: 0.4404} I was still a child {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Didn&#39;t get the chance to {&#39;neg&#39;: 0.303, &#39;neu&#39;: 0.697, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.1877} Feel the world around me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Had no time to choose {&#39;neg&#39;: 0.355, &#39;neu&#39;: 0.645, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.296} What I chose to do {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} So go easy on me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.557, &#39;pos&#39;: 0.443, &#39;compound&#39;: 0.4902} I had good intentions {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.408, &#39;pos&#39;: 0.592, &#39;compound&#39;: 0.4404} And the highest hopes {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.517, &#39;pos&#39;: 0.483, &#39;compound&#39;: 0.4215} But I know right now {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} That probably doesn&#39;t even show {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} Go easy on me, baby {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.58, &#39;pos&#39;: 0.42, &#39;compound&#39;: 0.4404} I was still a child {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I didn&#39;t get the chance to {&#39;neg&#39;: 0.303, &#39;neu&#39;: 0.697, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.1877} Feel the world around me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} I had no time to choose {&#39;neg&#39;: 0.355, &#39;neu&#39;: 0.645, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.296} What I chose to do {&#39;neg&#39;: 0.0, &#39;neu&#39;: 1.0, &#39;pos&#39;: 0.0, &#39;compound&#39;: 0.0} So go easy on me {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.557, &#39;pos&#39;: 0.443, &#39;compound&#39;: 0.4902} . Adele&#39;s song, &quot;Easy on Me&quot; had mostly neutral polarity scores. However this is an emotional/sad song about her past relationship. The frequency distribution of her lyrics reveal that the song is about herself as &quot;I&quot;, &quot;Go&quot;, &quot;Easy&quot;, &quot;On&quot; and &quot;Me&quot; came up the most frequently. . Through our analysis, we found that the reception of an artist&#39;s songs, as well as the number of songs that are listened to, might be affected by the origin country of the artist. . We also found that computerized text analysis may not be enough to perceive human emotions. As shown in Adele’s song “Easy On Me,” the Sentiment Intensity Analyzer averaged a score of 0.084, which meant that the song was very neutral with slight positive sentiment. However, this song is meant to be a very emotional reminiscence of the past with very slight hints of hopefulness. . For example, here are some lyrics with positive words: . I had good intentions And the highest hopes But I know right now That probably doesn&#39;t even show . In the context of the other negative lyrics, that mention that despite her hopes and good intentions, she still made bad choices, these positive lyrics don’t seem so positive. But our text analysis is not as good at tying verses together and reading this one positive verse in context of the rest of the song. This is a common problem in NLP in that it is hard for a computer to understand the context of a piece of writing, especially when the writing is of an artistic nature like song lyrics can be. . In Lil Nas X’s “Industry Baby,” the Sentiment Intensity Analyzer averaged a score of 0.129, which was also pretty neutral but again more on the positive side. This song is very different from Adele’s “Easy On Me,” yet they received very similar scores. This again demonstrates that computerized text analysis is not quite able to perceive human emotions as “Industry Baby” is a very upbeat and empowering hype song. . Discussion . This is important in the big picture because it starts to paint a picture of how songs spread over time and through countries. Although we were only able to look at 2 artists (Lil Nas X and Adele) in 2 countries (the US and UK), we already began to see the ways in which their songs were received in both of these countries. . Through our map analysis, we saw clear peaks of ranks a couple weeks to a month after release, and then a slow comedown of ranking and streaming after. The origin country of the artist seemed to have a big effect on how popular an artist’s songs were. . Through our text analysis, we found that two very different songs were at the top of the charts for the US and UK. Although they had similar Sentiment Intensity Analyzer scores, their message and genre of song varied. . This could potentially mean that people are more likely to listen to artists that are from the same country as them, but also could be confounded by marketing efforts being concentrated in an artist’s home country. However, knowing that an artist’s home country is more receptive to their music, and also that it normally takes a few weeks to a month for a song to truly climb the ranks, could be something to strongly consider when artists are figuring out where to hold events or shows promoting or showing their new music. . The sort of analysis that we did would be helpful to all artists, especially smaller artists that are trying to gain popularity and trying to target audiences in specific countries. .",
            "url": "https://spurthirallapalli.github.io/DH140SampleFastAI/fastpages/jupyter/2022/03/14/FinalProject.html",
            "relUrl": "/fastpages/jupyter/2022/03/14/FinalProject.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "My Title",
            "content": "Assignment 3 . Pandas and plotting exercises . import pandas as pd . In Week 2, you used a dataset from the CORGIS website. You may have used either the Python, CSV, or JSON data files. . For this assignment, use the CSV file format for the same category of data that you used previously. . # Use pandas read_csv function to import the data into a dataframe variable earthquakes = pd.read_csv(&#39;earthquakes.csv&#39;) . . There are 8394 rows and 18 columns. . # The info method (used above) gives information the column names as well earthquakes.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 8394 entries, 0 to 8393 Data columns (total 18 columns): # Column Non-Null Count Dtype -- -- 0 id 8394 non-null object 1 impact.gap 8394 non-null float64 2 impact.magnitude 8394 non-null float64 3 impact.significance 8394 non-null int64 4 location.depth 8394 non-null float64 5 location.distance 8394 non-null float64 6 location.full 8394 non-null object 7 location.latitude 8394 non-null float64 8 location.longitude 8394 non-null float64 9 location.name 8394 non-null object 10 time.day 8394 non-null int64 11 time.epoch 8394 non-null int64 12 time.full 8394 non-null object 13 time.hour 8394 non-null int64 14 time.minute 8394 non-null int64 15 time.month 8394 non-null int64 16 time.second 8394 non-null int64 17 time.year 8394 non-null int64 dtypes: float64(6), int64(8), object(4) memory usage: 1.2+ MB . There are 18 columns. The column names are: id, impact.gap, impact.magnitude, impact.significance, location.depth, location.distance, location.full, location.latitude, location.longitude, location.name, time.day, time.epoch, time.full, time.hour, time.minute, time.month, time.second, and time.year. . # Once again, the info method gives information about this in the last column. earthquakes.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 8394 entries, 0 to 8393 Data columns (total 18 columns): # Column Non-Null Count Dtype -- -- 0 id 8394 non-null object 1 impact.gap 8394 non-null float64 2 impact.magnitude 8394 non-null float64 3 impact.significance 8394 non-null int64 4 location.depth 8394 non-null float64 5 location.distance 8394 non-null float64 6 location.full 8394 non-null object 7 location.latitude 8394 non-null float64 8 location.longitude 8394 non-null float64 9 location.name 8394 non-null object 10 time.day 8394 non-null int64 11 time.epoch 8394 non-null int64 12 time.full 8394 non-null object 13 time.hour 8394 non-null int64 14 time.minute 8394 non-null int64 15 time.month 8394 non-null int64 16 time.second 8394 non-null int64 17 time.year 8394 non-null int64 dtypes: float64(6), int64(8), object(4) memory usage: 1.2+ MB . The datatypes of each column are: id -- object, impact.gap -- float64, impact.magnitude -- float64, impact.significance -- int64, location.depth -- float64, location.distance -- float64, location.full -- object, location.latitude -- float64, location.longitude -- float64, location.name -- object, time.day -- int64, time.epoch -- int64, time.full -- object, time.hour -- int64, time.minute -- int64, time.month -- int64, time.second -- int64, and time.year -- int64. . # head(2) will allow me to look at the first two rows earthquakes.head(2) . id impact.gap impact.magnitude impact.significance location.depth location.distance location.full location.latitude location.longitude location.name time.day time.epoch time.full time.hour time.minute time.month time.second time.year . 0 nc72666881 | 122.0 | 1.43 | 31 | 15.12 | 0.1034 | 13km E of Livermore, California | 37.672333 | -121.6190 | California | 27 | 1469593183550 | 2016-07-27 00:19:43 | 0 | 19 | 7 | 43 | 2016 | . 1 us20006i0y | 30.0 | 4.90 | 371 | 97.07 | 1.4390 | 58km WNW of Pakokku, Burma | 21.514600 | 94.5721 | Burma | 27 | 1469593228220 | 2016-07-27 00:20:28 | 0 | 20 | 7 | 28 | 2016 | . # tail(2) will allow me to look at the first two rows earthquakes.tail(2) . id impact.gap impact.magnitude impact.significance location.depth location.distance location.full location.latitude location.longitude location.name time.day time.epoch time.full time.hour time.minute time.month time.second time.year . 8392 ci37672328 | 103.0 | 1.55 | 37 | 29.25 | 0.06980 | 6km NNW of Chatsworth, CA | 34.308000 | -118.635333 | California | 25 | 1472182571880 | 2016-08-25 23:36:11 | 23 | 36 | 8 | 11 | 2016 | . 8393 ci37672360 | 99.0 | 0.89 | 12 | 8.29 | 0.02562 | 14km NE of Yucaipa, CA | 34.119167 | -116.933667 | California | 25 | 1472183881830 | 2016-08-25 23:58:01 | 23 | 58 | 8 | 1 | 2016 | . # describe() module allows us to print summary stats earthquakes.describe() . impact.gap impact.magnitude impact.significance location.depth location.distance location.latitude location.longitude time.day time.epoch time.hour time.minute time.month time.second time.year . count 8394.000000 | 8394.000000 | 8394.000000 | 8394.000000 | 8394.000000 | 8394.000000 | 8394.000000 | 8394.000000 | 8.394000e+03 | 8394.000000 | 8394.000000 | 8394.000000 | 8394.000000 | 8394.0 | . mean 111.832581 | 1.512941 | 56.343817 | 23.051817 | 0.375820 | 39.713009 | -111.863853 | 14.999047 | 1.470799e+12 | 11.323922 | 29.326662 | 7.821777 | 29.277341 | 2016.0 | . std 81.410408 | 1.152668 | 96.677536 | 51.081531 | 1.547686 | 18.404840 | 62.943337 | 9.223647 | 7.281744e+08 | 6.967305 | 17.303331 | 0.382723 | 17.146283 | 0.0 | . min 0.000000 | 0.010000 | 0.000000 | -3.390000 | 0.000000 | -59.611900 | -179.978000 | 1.000000 | 1.469593e+12 | 0.000000 | 0.000000 | 7.000000 | 0.000000 | 2016.0 | . 25% 57.000000 | 0.740000 | 8.000000 | 3.800000 | 0.006667 | 34.051542 | -146.522150 | 7.000000 | 1.470182e+12 | 5.000000 | 14.000000 | 8.000000 | 15.000000 | 2016.0 | . 50% 96.000000 | 1.200000 | 22.000000 | 8.900000 | 0.051300 | 38.272100 | -119.737350 | 14.000000 | 1.470752e+12 | 11.000000 | 29.000000 | 8.000000 | 29.000000 | 2016.0 | . 75% 156.000000 | 1.880000 | 54.000000 | 15.800000 | 0.167650 | 51.808350 | -116.717500 | 23.000000 | 1.471398e+12 | 17.000000 | 44.000000 | 8.000000 | 44.000000 | 2016.0 | . max 358.000000 | 7.700000 | 2674.000000 | 622.130000 | 40.547000 | 84.029100 | 179.959400 | 31.000000 | 1.472184e+12 | 23.000000 | 59.000000 | 8.000000 | 59.000000 | 2016.0 | . # In the form df[columnname] -- I&#39;ll be looking at the time.day column earthquakes[&#39;time.day&#39;] . 0 27 1 27 2 27 3 27 4 27 .. 8389 25 8390 25 8391 25 8392 25 8393 25 Name: time.day, Length: 8394, dtype: int64 . # I&#39;m picking the impact.magnitude column, which &quot;is a measure of the size of an earthquake at its source&quot;. # It is numerical and typically ranges from -1 to 10 (least -&gt; most powerful) # I&#39;m picking the x value to be id and the y value to be the magnitude earthquakes.plot(x=&#39;id&#39;, y=&#39;impact.magnitude&#39;) . &lt;AxesSubplot:xlabel=&#39;id&#39;&gt; . I am going to try to make the plot bigger, since there are so many data values, to see if it will clean up the plot a bit. . earthquakes.plot(x=&#39;id&#39;, y=&#39;impact.magnitude&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;id&#39;&gt; . This made it a bit better, but not by that much. There&#39;s too many datapoints to see this data very well. I&#39;ll also try to do this plot again by sorting the data to see if it forms a clear line/plot, and to see what range of values this graph produces. . earthquakes.sort_values(by=&#39;impact.magnitude&#39;).plot(x=&#39;id&#39;, y=&#39;impact.magnitude&#39;, figsize=(20,5)) . &lt;AxesSubplot:xlabel=&#39;id&#39;&gt; . The flatter the line between two points, it means that there was more frequency in that range. So we can see that there are a bunch of smaller earthquakess, but as we approach a higher magnitude, there are less of them. . earthquakes.loc[[0,1,2,3,4,5,6,7,8,9], [&#39;impact.magnitude&#39;]] . impact.magnitude . 0 1.43 | . 1 4.90 | . 2 0.06 | . 3 0.40 | . 4 0.30 | . 5 1.80 | . 6 1.00 | . 7 2.00 | . 8 1.20 | . 9 1.67 | . # as well as the matching 10 elements of a different column that has interesting text # The column I chose for text is location.name # In order to get the first 10 values, I needed to provide indices for them (0-&gt;9) earthquakes.loc[[0,1,2,3,4,5,6,7,8,9], [&#39;impact.magnitude&#39;, &#39;location.name&#39;]] . impact.magnitude location.name . 0 1.43 | California | . 1 4.90 | Burma | . 2 0.06 | California | . 3 0.40 | California | . 4 0.30 | Nevada | . 5 1.80 | Alaska | . 6 1.00 | Hawaii | . 7 2.00 | Alaska | . 8 1.20 | California | . 9 1.67 | California | . # and make a bar plot with the text values horizontally and the numeric values as the bar heights # magLoc means magnitude and location, since these are the two values that I saved magLoc = earthquakes.loc[[0,1,2,3,4,5,6,7,8,9], [&#39;impact.magnitude&#39;, &#39;location.name&#39;]] magLoc.plot(kind=&#39;bar&#39;, x=&#39;location.name&#39;) . &lt;AxesSubplot:xlabel=&#39;location.name&#39;&gt; . magLoc.plot(kind=&#39;barh&#39;, x=&#39;location.name&#39;) . &lt;AxesSubplot:ylabel=&#39;location.name&#39;&gt; . # and change at least two aesthetic elements (colors, labels, titles, ...) # Make the earthquakes that happen in &quot;California&quot; in purple barcolors = [] for i in magLoc.index: if magLoc.loc[i,&#39;location.name&#39;] in [&#39;California&#39;]: barcolors.append(&#39;purple&#39;) else: barcolors.append(&#39;grey&#39;) print(barcolors) . [&#39;purple&#39;, &#39;grey&#39;, &#39;purple&#39;, &#39;purple&#39;, &#39;grey&#39;, &#39;grey&#39;, &#39;grey&#39;, &#39;grey&#39;, &#39;purple&#39;, &#39;purple&#39;] . ax = magLoc.plot(kind=&#39;barh&#39;, x=&#39;location.name&#39;, y=&#39;impact.magnitude&#39;, color=barcolors) ax.legend([&#39;Magnitude of Earthquake&#39;]) . &lt;matplotlib.legend.Legend at 0x7fc918c1c2b0&gt; . Free form section . Choose another type of plot that interests you from the pandas.DataFrame.plot documentation [look at the &#39;kind&#39; parameter] and make a new plot of your dataset values using the plot type | . dotcolors = [] for i in magLoc.index: if magLoc.loc[i,&#39;location.name&#39;] in [&#39;California&#39;]: dotcolors.append(&#39;purple&#39;) elif magLoc.loc[i,&#39;location.name&#39;] in [&#39;Burma&#39;]: dotcolors.append(&#39;blue&#39;) elif magLoc.loc[i,&#39;location.name&#39;] in [&#39;Nevada&#39;]: dotcolors.append(&#39;red&#39;) elif magLoc.loc[i,&#39;location.name&#39;] in [&#39;Alaska&#39;]: dotcolors.append(&#39;pink&#39;) else: dotcolors.append(&#39;green&#39;) ax = magLoc.plot(kind=&#39;scatter&#39;, x=&#39;location.name&#39;, y=&#39;impact.magnitude&#39;, color=dotcolors) ax.legend([&#39;Magnitude of Earthquake&#39;]) . &lt;matplotlib.legend.Legend at 0x7fc918b22cd0&gt; . Copy some of your analysis from the Week 2 assignment into new cells below | Clean them up if desired, and make sure that you translate them to work with your new pandas dataframe structure here if needed | Create several plots to complement and extend your analysis | . In the week 2 assignment, I did a couple of operations with mathematical operators, functions, and modules to work with the data. In the following section, I will try to replicate some of thesee features using csv data as opposed to python data, and add some more plots and analysis. . # Use the loc method earthquakes.loc[[0]] . id impact.gap impact.magnitude impact.significance location.depth location.distance location.full location.latitude location.longitude location.name time.day time.epoch time.full time.hour time.minute time.month time.second time.year . 0 nc72666881 | 122.0 | 1.43 | 31 | 15.12 | 0.1034 | 13km E of Livermore, California | 37.672333 | -121.619 | California | 27 | 1469593183550 | 2016-07-27 00:19:43 | 0 | 19 | 7 | 43 | 2016 | . Now, I want to try implementing a mathematical operation. For this very first data value (shown above), I will multiply the depth value by 1000 to change the units from km to m. . Note: According to this webpage, the depth of an earthquake is measured in kilometers. . #modified: earthquake_data[0][&#39;location&#39;][&#39;depth&#39;] -&gt; earthquakes.loc[0, &#39;location.depth&#39;] depth_meters = earthquakes.loc[0, &#39;location.depth&#39;] * 1000 print(&quot;Depth in meters is: &quot; + str(depth_meters) + &quot; meters.&quot;) . Depth in meters is: 15120.0 meters. . This matches last weeks assignment, which produced the same result. . Now, I&#39;m going to experiment with conditional expressions. According to this website, also listed in the mathematical operations section, mentions that &quot;Shallow earthquakes are between 0 and 70 km deep; intermediate earthquakes, 70 - 300 km deep; and deep earthquakes, 300 - 700 km deep&quot;, which I am going to apply to the first data value. . # 0-&gt;70 km = Shallow # 70-&gt;300 km = Intermediate # 300-&gt;700 k = Deep #modified: earthquake_data[0][&#39;location&#39;][&#39;depth&#39;] -&gt; earthquakes.loc[0, &#39;location.depth&#39;] if (earthquakes.loc[0, &#39;location.depth&#39;] &lt; 70): print(&quot;This is a shallow earthquake.&quot;) elif (earthquakes.loc[0, &#39;location.depth&#39;] &lt; 300): print(&quot;This is an intermediate earthquake&quot;) else: print(&quot;This is an deep earthquake&quot;) . This is a shallow earthquake. . This matches last weeks assignment, which produced the same result. . In the following section, I&#39;m going to use loc/iloc to find all the deep earthquakes and plot their values. I don&#39;t think for loops are needed here because loc/iloc takes care of that. . earthquakes.loc[earthquakes[&#39;location.depth&#39;] &gt; 300] . id impact.gap impact.magnitude impact.significance location.depth location.distance location.full location.latitude location.longitude location.name time.day time.epoch time.full time.hour time.minute time.month time.second time.year . 112 us100069gq | 84.0 | 4.4 | 298 | 540.25 | 4.539 | 192km NE of Ndoi Island, Fiji | -19.3536 | -177.4688 | Fiji | 27 | 1469629337280 | 2016-07-27 10:22:17 | 10 | 22 | 7 | 17 | 2016 | . 226 us100069i2 | 176.0 | 4.4 | 298 | 599.55 | 8.139 | South of the Fiji Islands | -25.9135 | 178.4949 | South of the Fiji Islands | 27 | 1469666202670 | 2016-07-27 20:36:42 | 20 | 36 | 7 | 42 | 2016 | . 698 us100069r1 | 257.0 | 4.0 | 246 | 442.35 | 5.700 | 174km WSW of L&#39;Esperance Rock, New Zealand | -31.9132 | 179.3506 | New Zealand | 29 | 1469802600160 | 2016-07-29 10:30:00 | 10 | 30 | 7 | 0 | 2016 | . 1115 us100068va | 94.0 | 4.5 | 312 | 534.48 | 5.766 | South of the Fiji Islands | -23.7475 | -179.9510 | South of the Fiji Islands | 30 | 1469912128690 | 2016-07-30 16:55:28 | 16 | 55 | 7 | 28 | 2016 | . 1277 us10006a4d | 159.0 | 4.4 | 298 | 552.91 | 4.961 | 108km S of Ndoi Island, Fiji | -21.6264 | -178.6404 | Fiji | 31 | 1469957607890 | 2016-07-31 05:33:27 | 5 | 33 | 7 | 27 | 2016 | . 1285 us10006a4i | 148.0 | 4.4 | 298 | 568.61 | 4.725 | 148km ENE of Ndoi Island, Fiji | -19.9161 | -177.5090 | Fiji | 31 | 1469958617080 | 2016-07-31 05:50:17 | 5 | 50 | 7 | 17 | 2016 | . 1291 us100068yc | 63.0 | 4.9 | 369 | 510.15 | 5.648 | South of the Fiji Islands | -23.8527 | -179.8836 | South of the Fiji Islands | 31 | 1469960394250 | 2016-07-31 06:19:54 | 6 | 19 | 7 | 54 | 2016 | . 1319 us10006901 | 86.0 | 4.5 | 312 | 504.34 | 3.830 | South of the Fiji Islands | -26.2414 | 179.3729 | South of the Fiji Islands | 31 | 1469970423830 | 2016-07-31 09:07:03 | 9 | 7 | 7 | 3 | 2016 | . 1400 us10006915 | 153.0 | 4.1 | 259 | 313.51 | 3.377 | 185km N of Kuril&#39;sk, Russia | 46.9009 | 147.6890 | Russia | 31 | 1469992902520 | 2016-07-31 15:21:42 | 15 | 21 | 7 | 42 | 2016 | . 1463 us1000692q | 82.0 | 4.4 | 298 | 536.01 | 3.463 | 284km SSE of Tabiauan, Philippines | 3.7369 | 123.0631 | Philippines | 31 | 1470013999200 | 2016-07-31 21:13:19 | 21 | 13 | 7 | 19 | 2016 | . 1497 us10006acb | 168.0 | 4.0 | 246 | 513.20 | 4.578 | South of the Fiji Islands | -25.1055 | 179.8371 | South of the Fiji Islands | 1 | 1470024873220 | 2016-08-01 00:14:33 | 0 | 14 | 8 | 33 | 2016 | . 1508 us1000693g | 101.0 | 4.6 | 326 | 509.04 | 4.844 | South of the Fiji Islands | -24.8047 | 179.8540 | South of the Fiji Islands | 1 | 1470028316980 | 2016-08-01 01:11:56 | 1 | 11 | 8 | 56 | 2016 | . 1544 us10006949 | 97.0 | 4.4 | 298 | 303.82 | 3.531 | 31km W of Agrihan, Northern Mariana Islands | 18.7680 | 145.3657 | Northern Mariana Islands | 1 | 1470035287100 | 2016-08-01 03:08:07 | 3 | 8 | 8 | 7 | 2016 | . 1711 us10006996 | 52.0 | 4.3 | 284 | 564.06 | 3.254 | 271km SE of Lambasa, Fiji | -17.8301 | -178.5327 | Fiji | 1 | 1470073523490 | 2016-08-01 13:45:23 | 13 | 45 | 8 | 23 | 2016 | . 2045 us10006af1 | 178.0 | 4.3 | 284 | 528.57 | 6.002 | South of the Fiji Islands | -23.4608 | -179.8971 | South of the Fiji Islands | 2 | 1470167385530 | 2016-08-02 15:49:45 | 15 | 49 | 8 | 45 | 2016 | . 2068 us10006af2 | 103.0 | 4.5 | 312 | 622.13 | 6.191 | Vanuatu region | -14.9295 | 172.3000 | Vanuatu region | 2 | 1470173941310 | 2016-08-02 17:39:01 | 17 | 39 | 8 | 1 | 2016 | . 2078 us10006af3 | 175.0 | 4.2 | 271 | 501.74 | 6.979 | South of the Fiji Islands | -24.5027 | -179.9427 | South of the Fiji Islands | 2 | 1470176180820 | 2016-08-02 18:16:20 | 18 | 16 | 8 | 20 | 2016 | . 2104 us10006afc | 81.0 | 4.4 | 298 | 523.19 | 5.469 | 152km ESE of Ndoi Island, Fiji | -21.0197 | -177.2917 | Fiji | 2 | 1470185183580 | 2016-08-02 20:46:23 | 20 | 46 | 8 | 23 | 2016 | . 2267 us100069q5 | 37.0 | 4.5 | 312 | 611.84 | 3.146 | 276km N of Ndoi Island, Fiji | -18.1535 | -178.6700 | Fiji | 3 | 1470230463180 | 2016-08-03 09:21:03 | 9 | 21 | 8 | 3 | 2016 | . 2298 us100069sl | 89.0 | 4.4 | 298 | 553.62 | 4.262 | 59km NE of Ndoi Island, Fiji | -20.2611 | -178.2997 | Fiji | 3 | 1470238008360 | 2016-08-03 11:26:48 | 11 | 26 | 8 | 48 | 2016 | . 2384 us10006afw | 79.0 | 4.2 | 271 | 526.13 | 2.999 | 235km SE of Lambasa, Fiji | -17.6380 | -178.8027 | Fiji | 3 | 1470263999630 | 2016-08-03 18:39:59 | 18 | 39 | 8 | 59 | 2016 | . 2402 us10006afx | 143.0 | 4.4 | 298 | 538.08 | 3.652 | 294km NNE of Ndoi Island, Fiji | -18.0490 | -178.1246 | Fiji | 3 | 1470268349840 | 2016-08-03 19:52:29 | 19 | 52 | 8 | 29 | 2016 | . 2719 us10006a2k | 13.0 | 6.3 | 611 | 510.00 | 2.145 | 70km ENE of Iwo Jima, Japan | 24.9477 | 142.0074 | Japan | 4 | 1470327873540 | 2016-08-04 12:24:33 | 12 | 24 | 8 | 33 | 2016 | . 3093 us10006bsv | 77.0 | 4.4 | 298 | 567.13 | 4.506 | 34km SSE of Ndoi Island, Fiji | -20.9321 | -178.5556 | Fiji | 5 | 1470452387980 | 2016-08-05 22:59:47 | 22 | 59 | 8 | 47 | 2016 | . 3109 us10006bsz | 74.0 | 4.1 | 259 | 599.18 | 3.331 | 289km N of Ndoi Island, Fiji | -18.0412 | -178.4624 | Fiji | 5 | 1470455086500 | 2016-08-05 23:44:46 | 23 | 44 | 8 | 46 | 2016 | . 3180 us10006btm | 124.0 | 4.3 | 284 | 573.68 | 5.362 | South of the Fiji Islands | -23.0231 | 179.2082 | South of the Fiji Islands | 6 | 1470470336240 | 2016-08-06 03:58:56 | 3 | 58 | 8 | 56 | 2016 | . 3376 us10006ccd | 131.0 | 4.0 | 246 | 342.80 | 6.767 | 213km WNW of Farallon de Pajaros, Northern Mar... | 21.5472 | 143.1465 | Northern Mariana Islands | 6 | 1470527381330 | 2016-08-06 19:49:41 | 19 | 49 | 8 | 41 | 2016 | . 3751 us10006cwr | 143.0 | 4.3 | 284 | 503.77 | 7.122 | South of the Fiji Islands | -24.6090 | -179.7836 | South of the Fiji Islands | 8 | 1470629761640 | 2016-08-08 00:16:01 | 0 | 16 | 8 | 1 | 2016 | . 3914 us10006c1y | 128.0 | 4.5 | 312 | 372.28 | 3.146 | 116km WSW of L&#39;Esperance Rock, New Zealand | -31.8191 | 179.9594 | New Zealand | 8 | 1470664387390 | 2016-08-08 09:53:07 | 9 | 53 | 8 | 7 | 2016 | . 4029 us10006c6w | 76.0 | 4.4 | 298 | 531.25 | 5.819 | South of the Fiji Islands | -23.6888 | -179.9401 | South of the Fiji Islands | 8 | 1470697343920 | 2016-08-08 19:02:23 | 19 | 2 | 8 | 23 | 2016 | . 4129 us10006cys | 186.0 | 4.2 | 271 | 498.50 | 12.956 | South of the Fiji Islands | -24.6560 | -179.9177 | South of the Fiji Islands | 9 | 1470728468380 | 2016-08-09 03:41:08 | 3 | 41 | 8 | 8 | 2016 | . 4130 us10006cyu | 152.0 | 4.0 | 246 | 360.41 | 2.900 | 229km SW of Vostok, Russia | 47.3008 | 146.9788 | Russia | 9 | 1470728648370 | 2016-08-09 03:44:08 | 3 | 44 | 8 | 8 | 2016 | . 4563 us10006cn4 | 178.0 | 4.3 | 284 | 583.34 | 3.038 | 246km SE of Lambasa, Fiji | -17.7464 | -178.7591 | Fiji | 10 | 1470849096270 | 2016-08-10 13:11:36 | 13 | 11 | 8 | 36 | 2016 | . 5045 us10006d6y | 54.0 | 4.5 | 312 | 484.69 | 2.354 | 265km WNW of Chichi-shima, Japan | 27.8826 | 139.6848 | Japan | 12 | 1470976076080 | 2016-08-12 00:27:56 | 0 | 27 | 8 | 56 | 2016 | . 5251 us10006dfc | 70.0 | 4.2 | 271 | 433.16 | 1.551 | 175km W of Chichi-shima, Japan | 26.9857 | 140.4491 | Japan | 12 | 1471030787490 | 2016-08-12 15:39:47 | 15 | 39 | 8 | 47 | 2016 | . 5579 us10006dn0 | 68.0 | 4.5 | 312 | 333.35 | 1.600 | 175km WSW of Hachijo-jima, Japan | 32.5988 | 138.0139 | Japan | 13 | 1471124976500 | 2016-08-13 17:49:36 | 17 | 49 | 8 | 36 | 2016 | . 5744 us10006drq | 72.0 | 4.9 | 369 | 510.23 | 5.174 | South of the Fiji Islands | -24.3012 | -179.7104 | South of the Fiji Islands | 14 | 1471183623840 | 2016-08-14 10:07:03 | 10 | 7 | 8 | 3 | 2016 | . 5750 us10006drv | 55.0 | 4.4 | 298 | 514.52 | 3.798 | Fiji region | -17.8283 | -177.9619 | Fiji region | 14 | 1471185466020 | 2016-08-14 10:37:46 | 10 | 37 | 8 | 46 | 2016 | . 5853 us10006du0 | 57.0 | 4.4 | 298 | 444.17 | 4.364 | 140km SW of Leksula, Indonesia | -4.4948 | 125.4738 | Indonesia | 14 | 1471226063170 | 2016-08-14 21:54:23 | 21 | 54 | 8 | 23 | 2016 | . 6056 us10006f32 | 145.0 | 4.2 | 271 | 574.40 | 2.389 | 147km NNW of Kimbe, Papua New Guinea | -4.3163 | 149.6298 | Papua New Guinea | 15 | 1471301099310 | 2016-08-15 18:44:59 | 18 | 44 | 8 | 59 | 2016 | . 6421 us10006efk | 19.0 | 4.9 | 369 | 548.09 | 2.382 | 118km NNW of Kimbe, Papua New Guinea | -4.5952 | 149.6539 | Papua New Guinea | 17 | 1471446714370 | 2016-08-17 11:11:54 | 11 | 11 | 8 | 54 | 2016 | . 6422 us10006efq | 33.0 | 4.8 | 354 | 568.99 | 3.410 | 118km NNW of Kimbe, Papua New Guinea | -4.6014 | 149.6447 | Papua New Guinea | 17 | 1471446791870 | 2016-08-17 11:13:11 | 11 | 13 | 8 | 11 | 2016 | . 6434 us10006fta | 137.0 | 4.2 | 271 | 366.98 | 3.384 | 138km WSW of L&#39;Esperance Rock, New Zealand | -32.0265 | 179.8177 | New Zealand | 17 | 1471450455360 | 2016-08-17 12:14:15 | 12 | 14 | 8 | 15 | 2016 | . 6846 us10006f0p | 103.0 | 4.3 | 284 | 470.93 | 5.032 | 92km SE of Ndoi Island, Fiji | -21.3299 | -178.1818 | Fiji | 19 | 1471610407080 | 2016-08-19 08:40:07 | 8 | 40 | 8 | 7 | 2016 | . 6875 us10006f4n | 166.0 | 4.2 | 271 | 317.32 | 3.859 | 225km W of Severo-Kuril&#39;sk, Russia | 50.6225 | 152.9402 | Russia | 19 | 1471621698730 | 2016-08-19 11:48:18 | 11 | 48 | 8 | 18 | 2016 | . 7350 us10006fl7 | 41.0 | 4.5 | 312 | 519.83 | 3.198 | 259km SE of Lambasa, Fiji | -17.7203 | -178.5915 | Fiji | 21 | 1471793577030 | 2016-08-21 11:32:57 | 11 | 32 | 8 | 57 | 2016 | . 7545 us10006fq7 | 66.0 | 5.6 | 483 | 404.41 | 3.261 | Izu Islands, Japan region | 29.8965 | 139.1312 | Japan region | 22 | 1471858388650 | 2016-08-22 05:33:08 | 5 | 33 | 8 | 8 | 2016 | . 7863 us10006g2n | 11.0 | 6.0 | 554 | 532.40 | 1.359 | 132km N of Nebe, Indonesia | -7.2805 | 122.4255 | Indonesia | 23 | 1471981184660 | 2016-08-23 15:39:44 | 15 | 39 | 8 | 44 | 2016 | . 7864 us10006gj0 | 13.0 | 5.8 | 518 | 514.33 | 6.129 | 140km N of Palue, Indonesia | -7.2081 | 122.5412 | Indonesia | 23 | 1471981246230 | 2016-08-23 15:40:46 | 15 | 40 | 8 | 46 | 2016 | . 7906 us10006g77 | 72.0 | 4.2 | 271 | 397.25 | 5.550 | 88km SSW of Leksula, Indonesia | -4.5144 | 126.2058 | Indonesia | 23 | 1471997620340 | 2016-08-23 20:13:40 | 20 | 13 | 8 | 40 | 2016 | . 7927 us10006g81 | 75.0 | 4.4 | 298 | 522.01 | 4.783 | 150km ENE of Ndoi Island, Fiji | -19.9531 | -177.4594 | Fiji | 23 | 1472006271150 | 2016-08-23 22:37:51 | 22 | 37 | 8 | 51 | 2016 | . 7942 us10006g8p | 84.0 | 4.6 | 326 | 528.84 | 1.836 | 30km SSW of Palimbang, Philippines | 5.9494 | 124.1084 | Philippines | 24 | 1472012210980 | 2016-08-24 00:16:50 | 0 | 16 | 8 | 50 | 2016 | . 8274 us20006tvk | 81.0 | 4.7 | 340 | 561.20 | 5.646 | South of the Fiji Islands | -23.3085 | 179.2413 | South of the Fiji Islands | 25 | 1472137849390 | 2016-08-25 11:10:49 | 11 | 10 | 8 | 49 | 2016 | . 8303 us20006ty8 | 48.0 | 5.9 | 536 | 456.00 | 3.002 | Izu Islands, Japan region | 30.6151 | 137.8462 | Japan region | 25 | 1472144683260 | 2016-08-25 13:04:43 | 13 | 4 | 8 | 43 | 2016 | . From a quick glance above, this seemed to work! . Now, I&#39;m going to plot these values, first with a scatter plot. . deepquakes = earthquakes.loc[earthquakes[&#39;location.depth&#39;] &gt; 300] deepquakes . id impact.gap impact.magnitude impact.significance location.depth location.distance location.full location.latitude location.longitude location.name time.day time.epoch time.full time.hour time.minute time.month time.second time.year . 112 us100069gq | 84.0 | 4.4 | 298 | 540.25 | 4.539 | 192km NE of Ndoi Island, Fiji | -19.3536 | -177.4688 | Fiji | 27 | 1469629337280 | 2016-07-27 10:22:17 | 10 | 22 | 7 | 17 | 2016 | . 226 us100069i2 | 176.0 | 4.4 | 298 | 599.55 | 8.139 | South of the Fiji Islands | -25.9135 | 178.4949 | South of the Fiji Islands | 27 | 1469666202670 | 2016-07-27 20:36:42 | 20 | 36 | 7 | 42 | 2016 | . 698 us100069r1 | 257.0 | 4.0 | 246 | 442.35 | 5.700 | 174km WSW of L&#39;Esperance Rock, New Zealand | -31.9132 | 179.3506 | New Zealand | 29 | 1469802600160 | 2016-07-29 10:30:00 | 10 | 30 | 7 | 0 | 2016 | . 1115 us100068va | 94.0 | 4.5 | 312 | 534.48 | 5.766 | South of the Fiji Islands | -23.7475 | -179.9510 | South of the Fiji Islands | 30 | 1469912128690 | 2016-07-30 16:55:28 | 16 | 55 | 7 | 28 | 2016 | . 1277 us10006a4d | 159.0 | 4.4 | 298 | 552.91 | 4.961 | 108km S of Ndoi Island, Fiji | -21.6264 | -178.6404 | Fiji | 31 | 1469957607890 | 2016-07-31 05:33:27 | 5 | 33 | 7 | 27 | 2016 | . 1285 us10006a4i | 148.0 | 4.4 | 298 | 568.61 | 4.725 | 148km ENE of Ndoi Island, Fiji | -19.9161 | -177.5090 | Fiji | 31 | 1469958617080 | 2016-07-31 05:50:17 | 5 | 50 | 7 | 17 | 2016 | . 1291 us100068yc | 63.0 | 4.9 | 369 | 510.15 | 5.648 | South of the Fiji Islands | -23.8527 | -179.8836 | South of the Fiji Islands | 31 | 1469960394250 | 2016-07-31 06:19:54 | 6 | 19 | 7 | 54 | 2016 | . 1319 us10006901 | 86.0 | 4.5 | 312 | 504.34 | 3.830 | South of the Fiji Islands | -26.2414 | 179.3729 | South of the Fiji Islands | 31 | 1469970423830 | 2016-07-31 09:07:03 | 9 | 7 | 7 | 3 | 2016 | . 1400 us10006915 | 153.0 | 4.1 | 259 | 313.51 | 3.377 | 185km N of Kuril&#39;sk, Russia | 46.9009 | 147.6890 | Russia | 31 | 1469992902520 | 2016-07-31 15:21:42 | 15 | 21 | 7 | 42 | 2016 | . 1463 us1000692q | 82.0 | 4.4 | 298 | 536.01 | 3.463 | 284km SSE of Tabiauan, Philippines | 3.7369 | 123.0631 | Philippines | 31 | 1470013999200 | 2016-07-31 21:13:19 | 21 | 13 | 7 | 19 | 2016 | . 1497 us10006acb | 168.0 | 4.0 | 246 | 513.20 | 4.578 | South of the Fiji Islands | -25.1055 | 179.8371 | South of the Fiji Islands | 1 | 1470024873220 | 2016-08-01 00:14:33 | 0 | 14 | 8 | 33 | 2016 | . 1508 us1000693g | 101.0 | 4.6 | 326 | 509.04 | 4.844 | South of the Fiji Islands | -24.8047 | 179.8540 | South of the Fiji Islands | 1 | 1470028316980 | 2016-08-01 01:11:56 | 1 | 11 | 8 | 56 | 2016 | . 1544 us10006949 | 97.0 | 4.4 | 298 | 303.82 | 3.531 | 31km W of Agrihan, Northern Mariana Islands | 18.7680 | 145.3657 | Northern Mariana Islands | 1 | 1470035287100 | 2016-08-01 03:08:07 | 3 | 8 | 8 | 7 | 2016 | . 1711 us10006996 | 52.0 | 4.3 | 284 | 564.06 | 3.254 | 271km SE of Lambasa, Fiji | -17.8301 | -178.5327 | Fiji | 1 | 1470073523490 | 2016-08-01 13:45:23 | 13 | 45 | 8 | 23 | 2016 | . 2045 us10006af1 | 178.0 | 4.3 | 284 | 528.57 | 6.002 | South of the Fiji Islands | -23.4608 | -179.8971 | South of the Fiji Islands | 2 | 1470167385530 | 2016-08-02 15:49:45 | 15 | 49 | 8 | 45 | 2016 | . 2068 us10006af2 | 103.0 | 4.5 | 312 | 622.13 | 6.191 | Vanuatu region | -14.9295 | 172.3000 | Vanuatu region | 2 | 1470173941310 | 2016-08-02 17:39:01 | 17 | 39 | 8 | 1 | 2016 | . 2078 us10006af3 | 175.0 | 4.2 | 271 | 501.74 | 6.979 | South of the Fiji Islands | -24.5027 | -179.9427 | South of the Fiji Islands | 2 | 1470176180820 | 2016-08-02 18:16:20 | 18 | 16 | 8 | 20 | 2016 | . 2104 us10006afc | 81.0 | 4.4 | 298 | 523.19 | 5.469 | 152km ESE of Ndoi Island, Fiji | -21.0197 | -177.2917 | Fiji | 2 | 1470185183580 | 2016-08-02 20:46:23 | 20 | 46 | 8 | 23 | 2016 | . 2267 us100069q5 | 37.0 | 4.5 | 312 | 611.84 | 3.146 | 276km N of Ndoi Island, Fiji | -18.1535 | -178.6700 | Fiji | 3 | 1470230463180 | 2016-08-03 09:21:03 | 9 | 21 | 8 | 3 | 2016 | . 2298 us100069sl | 89.0 | 4.4 | 298 | 553.62 | 4.262 | 59km NE of Ndoi Island, Fiji | -20.2611 | -178.2997 | Fiji | 3 | 1470238008360 | 2016-08-03 11:26:48 | 11 | 26 | 8 | 48 | 2016 | . 2384 us10006afw | 79.0 | 4.2 | 271 | 526.13 | 2.999 | 235km SE of Lambasa, Fiji | -17.6380 | -178.8027 | Fiji | 3 | 1470263999630 | 2016-08-03 18:39:59 | 18 | 39 | 8 | 59 | 2016 | . 2402 us10006afx | 143.0 | 4.4 | 298 | 538.08 | 3.652 | 294km NNE of Ndoi Island, Fiji | -18.0490 | -178.1246 | Fiji | 3 | 1470268349840 | 2016-08-03 19:52:29 | 19 | 52 | 8 | 29 | 2016 | . 2719 us10006a2k | 13.0 | 6.3 | 611 | 510.00 | 2.145 | 70km ENE of Iwo Jima, Japan | 24.9477 | 142.0074 | Japan | 4 | 1470327873540 | 2016-08-04 12:24:33 | 12 | 24 | 8 | 33 | 2016 | . 3093 us10006bsv | 77.0 | 4.4 | 298 | 567.13 | 4.506 | 34km SSE of Ndoi Island, Fiji | -20.9321 | -178.5556 | Fiji | 5 | 1470452387980 | 2016-08-05 22:59:47 | 22 | 59 | 8 | 47 | 2016 | . 3109 us10006bsz | 74.0 | 4.1 | 259 | 599.18 | 3.331 | 289km N of Ndoi Island, Fiji | -18.0412 | -178.4624 | Fiji | 5 | 1470455086500 | 2016-08-05 23:44:46 | 23 | 44 | 8 | 46 | 2016 | . 3180 us10006btm | 124.0 | 4.3 | 284 | 573.68 | 5.362 | South of the Fiji Islands | -23.0231 | 179.2082 | South of the Fiji Islands | 6 | 1470470336240 | 2016-08-06 03:58:56 | 3 | 58 | 8 | 56 | 2016 | . 3376 us10006ccd | 131.0 | 4.0 | 246 | 342.80 | 6.767 | 213km WNW of Farallon de Pajaros, Northern Mar... | 21.5472 | 143.1465 | Northern Mariana Islands | 6 | 1470527381330 | 2016-08-06 19:49:41 | 19 | 49 | 8 | 41 | 2016 | . 3751 us10006cwr | 143.0 | 4.3 | 284 | 503.77 | 7.122 | South of the Fiji Islands | -24.6090 | -179.7836 | South of the Fiji Islands | 8 | 1470629761640 | 2016-08-08 00:16:01 | 0 | 16 | 8 | 1 | 2016 | . 3914 us10006c1y | 128.0 | 4.5 | 312 | 372.28 | 3.146 | 116km WSW of L&#39;Esperance Rock, New Zealand | -31.8191 | 179.9594 | New Zealand | 8 | 1470664387390 | 2016-08-08 09:53:07 | 9 | 53 | 8 | 7 | 2016 | . 4029 us10006c6w | 76.0 | 4.4 | 298 | 531.25 | 5.819 | South of the Fiji Islands | -23.6888 | -179.9401 | South of the Fiji Islands | 8 | 1470697343920 | 2016-08-08 19:02:23 | 19 | 2 | 8 | 23 | 2016 | . 4129 us10006cys | 186.0 | 4.2 | 271 | 498.50 | 12.956 | South of the Fiji Islands | -24.6560 | -179.9177 | South of the Fiji Islands | 9 | 1470728468380 | 2016-08-09 03:41:08 | 3 | 41 | 8 | 8 | 2016 | . 4130 us10006cyu | 152.0 | 4.0 | 246 | 360.41 | 2.900 | 229km SW of Vostok, Russia | 47.3008 | 146.9788 | Russia | 9 | 1470728648370 | 2016-08-09 03:44:08 | 3 | 44 | 8 | 8 | 2016 | . 4563 us10006cn4 | 178.0 | 4.3 | 284 | 583.34 | 3.038 | 246km SE of Lambasa, Fiji | -17.7464 | -178.7591 | Fiji | 10 | 1470849096270 | 2016-08-10 13:11:36 | 13 | 11 | 8 | 36 | 2016 | . 5045 us10006d6y | 54.0 | 4.5 | 312 | 484.69 | 2.354 | 265km WNW of Chichi-shima, Japan | 27.8826 | 139.6848 | Japan | 12 | 1470976076080 | 2016-08-12 00:27:56 | 0 | 27 | 8 | 56 | 2016 | . 5251 us10006dfc | 70.0 | 4.2 | 271 | 433.16 | 1.551 | 175km W of Chichi-shima, Japan | 26.9857 | 140.4491 | Japan | 12 | 1471030787490 | 2016-08-12 15:39:47 | 15 | 39 | 8 | 47 | 2016 | . 5579 us10006dn0 | 68.0 | 4.5 | 312 | 333.35 | 1.600 | 175km WSW of Hachijo-jima, Japan | 32.5988 | 138.0139 | Japan | 13 | 1471124976500 | 2016-08-13 17:49:36 | 17 | 49 | 8 | 36 | 2016 | . 5744 us10006drq | 72.0 | 4.9 | 369 | 510.23 | 5.174 | South of the Fiji Islands | -24.3012 | -179.7104 | South of the Fiji Islands | 14 | 1471183623840 | 2016-08-14 10:07:03 | 10 | 7 | 8 | 3 | 2016 | . 5750 us10006drv | 55.0 | 4.4 | 298 | 514.52 | 3.798 | Fiji region | -17.8283 | -177.9619 | Fiji region | 14 | 1471185466020 | 2016-08-14 10:37:46 | 10 | 37 | 8 | 46 | 2016 | . 5853 us10006du0 | 57.0 | 4.4 | 298 | 444.17 | 4.364 | 140km SW of Leksula, Indonesia | -4.4948 | 125.4738 | Indonesia | 14 | 1471226063170 | 2016-08-14 21:54:23 | 21 | 54 | 8 | 23 | 2016 | . 6056 us10006f32 | 145.0 | 4.2 | 271 | 574.40 | 2.389 | 147km NNW of Kimbe, Papua New Guinea | -4.3163 | 149.6298 | Papua New Guinea | 15 | 1471301099310 | 2016-08-15 18:44:59 | 18 | 44 | 8 | 59 | 2016 | . 6421 us10006efk | 19.0 | 4.9 | 369 | 548.09 | 2.382 | 118km NNW of Kimbe, Papua New Guinea | -4.5952 | 149.6539 | Papua New Guinea | 17 | 1471446714370 | 2016-08-17 11:11:54 | 11 | 11 | 8 | 54 | 2016 | . 6422 us10006efq | 33.0 | 4.8 | 354 | 568.99 | 3.410 | 118km NNW of Kimbe, Papua New Guinea | -4.6014 | 149.6447 | Papua New Guinea | 17 | 1471446791870 | 2016-08-17 11:13:11 | 11 | 13 | 8 | 11 | 2016 | . 6434 us10006fta | 137.0 | 4.2 | 271 | 366.98 | 3.384 | 138km WSW of L&#39;Esperance Rock, New Zealand | -32.0265 | 179.8177 | New Zealand | 17 | 1471450455360 | 2016-08-17 12:14:15 | 12 | 14 | 8 | 15 | 2016 | . 6846 us10006f0p | 103.0 | 4.3 | 284 | 470.93 | 5.032 | 92km SE of Ndoi Island, Fiji | -21.3299 | -178.1818 | Fiji | 19 | 1471610407080 | 2016-08-19 08:40:07 | 8 | 40 | 8 | 7 | 2016 | . 6875 us10006f4n | 166.0 | 4.2 | 271 | 317.32 | 3.859 | 225km W of Severo-Kuril&#39;sk, Russia | 50.6225 | 152.9402 | Russia | 19 | 1471621698730 | 2016-08-19 11:48:18 | 11 | 48 | 8 | 18 | 2016 | . 7350 us10006fl7 | 41.0 | 4.5 | 312 | 519.83 | 3.198 | 259km SE of Lambasa, Fiji | -17.7203 | -178.5915 | Fiji | 21 | 1471793577030 | 2016-08-21 11:32:57 | 11 | 32 | 8 | 57 | 2016 | . 7545 us10006fq7 | 66.0 | 5.6 | 483 | 404.41 | 3.261 | Izu Islands, Japan region | 29.8965 | 139.1312 | Japan region | 22 | 1471858388650 | 2016-08-22 05:33:08 | 5 | 33 | 8 | 8 | 2016 | . 7863 us10006g2n | 11.0 | 6.0 | 554 | 532.40 | 1.359 | 132km N of Nebe, Indonesia | -7.2805 | 122.4255 | Indonesia | 23 | 1471981184660 | 2016-08-23 15:39:44 | 15 | 39 | 8 | 44 | 2016 | . 7864 us10006gj0 | 13.0 | 5.8 | 518 | 514.33 | 6.129 | 140km N of Palue, Indonesia | -7.2081 | 122.5412 | Indonesia | 23 | 1471981246230 | 2016-08-23 15:40:46 | 15 | 40 | 8 | 46 | 2016 | . 7906 us10006g77 | 72.0 | 4.2 | 271 | 397.25 | 5.550 | 88km SSW of Leksula, Indonesia | -4.5144 | 126.2058 | Indonesia | 23 | 1471997620340 | 2016-08-23 20:13:40 | 20 | 13 | 8 | 40 | 2016 | . 7927 us10006g81 | 75.0 | 4.4 | 298 | 522.01 | 4.783 | 150km ENE of Ndoi Island, Fiji | -19.9531 | -177.4594 | Fiji | 23 | 1472006271150 | 2016-08-23 22:37:51 | 22 | 37 | 8 | 51 | 2016 | . 7942 us10006g8p | 84.0 | 4.6 | 326 | 528.84 | 1.836 | 30km SSW of Palimbang, Philippines | 5.9494 | 124.1084 | Philippines | 24 | 1472012210980 | 2016-08-24 00:16:50 | 0 | 16 | 8 | 50 | 2016 | . 8274 us20006tvk | 81.0 | 4.7 | 340 | 561.20 | 5.646 | South of the Fiji Islands | -23.3085 | 179.2413 | South of the Fiji Islands | 25 | 1472137849390 | 2016-08-25 11:10:49 | 11 | 10 | 8 | 49 | 2016 | . 8303 us20006ty8 | 48.0 | 5.9 | 536 | 456.00 | 3.002 | Izu Islands, Japan region | 30.6151 | 137.8462 | Japan region | 25 | 1472144683260 | 2016-08-25 13:04:43 | 13 | 4 | 8 | 43 | 2016 | . deepquakes.plot(kind=&#39;scatter&#39;, x=&#39;impact.magnitude&#39;, y=&#39;location.depth&#39;) . &lt;AxesSubplot:xlabel=&#39;impact.magnitude&#39;, ylabel=&#39;location.depth&#39;&gt; . From looking above, it doesnt seem like there&#39;s a huge correlation between magnitude and depth. I&#39;ll try adding some more visual features to make this clear. . dotcolors = [] for i in deepquakes.index: if deepquakes.loc[i,&#39;location.depth&#39;] &lt; 300: dotcolors.append(&#39;grey&#39;) elif deepquakes.loc[i,&#39;location.depth&#39;] &gt;= 300 and deepquakes.loc[i,&#39;location.depth&#39;] &lt; 400: dotcolors.append(&#39;blue&#39;) elif deepquakes.loc[i,&#39;location.depth&#39;] &gt;= 400 and deepquakes.loc[i,&#39;location.depth&#39;] &lt; 500: dotcolors.append(&#39;purple&#39;) elif deepquakes.loc[i,&#39;location.depth&#39;] &gt;= 500 and deepquakes.loc[i,&#39;location.depth&#39;] &lt; 600: dotcolors.append(&#39;orange&#39;) else: dotcolors.append(&#39;red&#39;) deepquakes.plot(kind=&#39;scatter&#39;, x=&#39;impact.magnitude&#39;, y=&#39;location.depth&#39;, color=dotcolors) . &lt;AxesSubplot:xlabel=&#39;impact.magnitude&#39;, ylabel=&#39;location.depth&#39;&gt; . As we can see above, there does not seem to be any linear correlation between depth and magnitude. Let&#39;s also try this with a bar graph. . # We also want to sort the magnitudes (sort values) and make the chart bigger (figsize) for better visibility barcolors = [] for i in deepquakes.index: if deepquakes.loc[i,&#39;location.depth&#39;] &lt; 300: barcolors.append(&#39;grey&#39;) elif deepquakes.loc[i,&#39;location.depth&#39;] &gt;= 300 and deepquakes.loc[i,&#39;location.depth&#39;] &lt; 400: barcolors.append(&#39;blue&#39;) elif deepquakes.loc[i,&#39;location.depth&#39;] &gt;= 400 and deepquakes.loc[i,&#39;location.depth&#39;] &lt; 500: barcolors.append(&#39;purple&#39;) elif deepquakes.loc[i,&#39;location.depth&#39;] &gt;= 500 and deepquakes.loc[i,&#39;location.depth&#39;] &lt; 600: barcolors.append(&#39;orange&#39;) else: barcolors.append(&#39;red&#39;) deepquakes.sort_values(by=&#39;impact.magnitude&#39;).plot(kind=&#39;bar&#39;, x=&#39;impact.magnitude&#39;, y=&#39;location.depth&#39;, color=barcolors, figsize=(12,5)) . &lt;AxesSubplot:xlabel=&#39;impact.magnitude&#39;&gt; .",
            "url": "https://spurthirallapalli.github.io/DH140SampleFastAI/fastpages/jupyter/2022/03/08/Assignment03.html",
            "relUrl": "/fastpages/jupyter/2022/03/08/Assignment03.html",
            "date": " • Mar 8, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://spurthirallapalli.github.io/DH140SampleFastAI/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://spurthirallapalli.github.io/DH140SampleFastAI/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://spurthirallapalli.github.io/DH140SampleFastAI/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://spurthirallapalli.github.io/DH140SampleFastAI/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}